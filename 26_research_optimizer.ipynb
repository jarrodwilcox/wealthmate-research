{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "Intended Module: research_optimizer\n",
    "Author: Jarrod Wilcox\n",
    "Version: 0.2.1\n",
    "Date: 6/30/2020\n",
    "Contact:  jarrod@wealthmate.com\n",
    "\n",
    "research_optimizer is a basic research program to read a clean file, fully-populated, of prices adjusted for any distributions, or alternatively, a return file, and then to produce portfolio allocations with analytics comparing best allocations from scenario-based probability distributions of expected ln(1+Lr), or Rubinstein, utility with those from Markowitz's mean-variance approach.\n",
    "\n",
    "Distributed as is, with MIT license, suitable for education and research.\n",
    "\n",
    "Oldest installable dependencies tested:  python 3.8.3, numpy 1.15.4, scipy 1.4.1, pandas 1.03, \n",
    "jupyter 1.0.0, matplotlib 3.2.1, seaborn 0.10.1, cvxpy 1.1.1.\n",
    "\n",
    "SAMPLE INPUTS:\n",
    "journalfile='JOURNAL.txt'\n",
    "logfile='RUN39.txt'\n",
    "sample='40YR'\n",
    "meanfile='CDATA40/asset_mean.csv'\n",
    "codefile='CDATA40/equiv.csv'\n",
    "sourcefile='CDATA40/prices.csv'\n",
    "sourcetype='PRICES'\n",
    "Llist=[1, 2, 4, 8, 16]\n",
    "splithalf=1\n",
    "mod_method='sub_means'\n",
    "long_only=False\n",
    "return_interval=8\n",
    "worst=-0.99\n",
    "\n",
    "journalfile: a file to append a list of run input descriptors to be used as a directory for\n",
    "    various optimization runs\n",
    "\n",
    "logfile: a file that mirrors the printed program output for this set of inputs\n",
    "\n",
    "sample: arbitrary text describing the run to jog the researcher's memory\n",
    "\n",
    "meanfile: file containing estimated mean returns per period for any securities where a priori \n",
    "estimated returns are to have a designated mean applied to all member securities within an asset group\n",
    "\n",
    "codefile: a path to a csv file containing two columns, security tickers or other ids and\n",
    "    their asset categories  or \"NOGROUPS\"\n",
    "\n",
    "sourcefile: a path to a csv price or return file (sorted by oldest-first, regular dates and adjusted for dividends and interest) with column headers identifying the security (usually a ticker), with the left-most column 'Date'\n",
    "\n",
    "sourcetype:  designation of whether the return source is in terms of prices or returns.\n",
    "    \n",
    "Llist: a vector of risk aversion coefficients, with larger numbers representing more conservatism.\n",
    "\n",
    "splithalf: 0,1,or 2, with 0 signifying use whole sample, 1 to use first half to learn, and last half to test,\n",
    "    and 2 vice versa.\n",
    "\n",
    "mod_method:  In this version, use either 'mirror', to give no return modification, or 'sub_means', causing the program to modify returns to induce all members of a group  to have the same mean return within the learning sample.  The researcher may write their own function to modify or add rows to the return matrix.\n",
    "\n",
    "long_only: True induces allocation constraints insuring all allocations lie on the interval 0,1. False allows long-short funds (recommended only for research unless the user knows how to modify the return matrix or the constraints of the solution!).\n",
    "\n",
    "return_interval: Returns are calculated by a comparison of current price and the price from regular_interval\n",
    "    rows older\n",
    "\n",
    "worst= -0.99:  If the solution is feasible, constrains allocations not to produce a portfolio return for any scenario less than worst.  If no feasible solution exists, a \"best efforts\" solution is presented, along with a message than no solution can meet the constraints.\n",
    "\n",
    "Sample data files are included in the repository.\n",
    "\n",
    "\n",
    "EXPECTED OUTPUT:\n",
    "Produces screen output, a logfile with a printout of program input and results, and appends its input\n",
    "    descriptions to a journal file.\n",
    "\n",
    "An article \"Better Portfolios with Higher Moments\" by Jarrod Wilcox, to be published in the Journal of Asset Management in 2020, provides further details on the approach.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "DEPENDENCIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import fmin_slsqp as slsqp\n",
    "from datetime import datetime\n",
    "from math import exp, isnan\n",
    "try:\n",
    "    import cvxpy as cp    \n",
    "except:\n",
    "    print ('This version of research_optimizer requires installation of cvxpy.')\n",
    "    raise\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GET PRIOR ASSET RETURN MEANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_asset_means(meanfile=None):\n",
    "    try:\n",
    "        ameans=pd.read_csv(meanfile).values\n",
    "        means_lookup={row[0]:row[1] for row in ameans}\n",
    "        return(means_lookup)\n",
    "    except:\n",
    "        print('NO ASSET MEANS FOUND')\n",
    "        raise\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GET ASSET GROUP CATEGORIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get asset group codes\n",
    "def load_asset_codes(codefile=None):\n",
    "    try:\n",
    "        equivs=pd.read_csv(codefile).values\n",
    "        equivs=[x if isinstance(x[1],str) else [x[0],'NOGROUP'] for x in equivs]\n",
    "        lookup_group={}\n",
    "        for tick in equivs:\n",
    "            lookup_group[tick[0]]=tick[1]\n",
    "        members={}\n",
    "        categories=sorted(set([x[1] for x in equivs]))\n",
    "        for group in categories:\n",
    "            members[group]=[x[0] for x in equivs if x[1]==group]     \n",
    "        return(lookup_group,members)\n",
    "    except:\n",
    "        print('NO ASSET CATEGORIZATION FOUND')\n",
    "        raise\n",
    "\n",
    "#a,b=load_asset_codes('CDATA40/equiv.csv')\n",
    "#print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD INPUT PRICE FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_source(sourcefile):\n",
    "    try:\n",
    "        source=pd.read_csv(sourcefile)\n",
    "        temp=source.get('Date')\n",
    "        if not temp is None:\n",
    "            source.index=temp #watch out if date misstyped\n",
    "            source=source.drop(columns=['Date'])\n",
    "        return source\n",
    "    except:\n",
    "        print('NO SOURCE FOUND')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REARRANGE COLUMNS BY ASSET CLASS IF SOURCE IS RETURN FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rearrange(members,source):\n",
    "    cols=[tick for group in members for tick in members[group]]\n",
    "    source2=pd.DataFrame(columns=cols,index=source.index)\n",
    "    for tick in cols:\n",
    "        source2[tick]=source[tick]\n",
    "    return(source2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CALCULATE RETURNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_returns(prices2,return_interval):\n",
    "    price_data=np.array(prices2.values,dtype='float32')\n",
    "    price_data1=np.ones((price_data.shape[0],price_data.shape[1]))\n",
    "    price_data1[return_interval:]=price_data[:-return_interval]\n",
    "    returns=(price_data/price_data1)\n",
    "    returns=returns[return_interval:]-1. \n",
    "    returns_df=pd.DataFrame(returns)   \n",
    "    returns_df.columns=prices2.columns\n",
    "    returns_df.index=prices2.index[return_interval:]\n",
    "    return(returns_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COLLECT FURTHER STATISTICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rtn_summary(returns,tickers):\n",
    "    means=np.mean(returns,axis=0) \n",
    "    covs=np.cov(returns.T)\n",
    "    stdevs=np.std(returns,axis=0)\n",
    "    corrs=np.round_(np.corrcoef(returns.T),2)\n",
    "    corr=pd.DataFrame(corrs,columns=tickers)\n",
    "    #cov=pd.DataFrame(covs,columns=tickers)\n",
    "    means=pd.Series(means)\n",
    "    stdev=pd.Series(stdevs)\n",
    "    skews=stats.skew(returns,axis=0)\n",
    "    skew=pd.Series(skews)\n",
    "    kurts=stats.kurtosis(returns,axis=0,fisher=False)\n",
    "    kurt=pd.Series(kurts)\n",
    "    descript=pd.DataFrame({'TICKER':tickers,'MEAN':np.round(means,4),\n",
    "        'STDEV':np.round(stdev,4),'SKEW':np.round(skew,2),'KURT':np.round(kurt,2)})\n",
    "    combined=descript.join(corr,how='outer')      \n",
    "        \n",
    "    return (means,covs,skews,kurts,combined)\n",
    "#means,covs,skews,kurts=rtn_summary(returns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OPTIONALLY SPLIT SAMPLE INTO SMALLER LEARN AND VALIDATE SUBSAMPLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  learning_returns(rtns,splithalf=0):\n",
    "    #rtns is np array, not dataframe\n",
    "    nrows = rtns.shape[0]\n",
    "    #set up split sample if desired\n",
    "    if splithalf not in [0,1,2]:\n",
    "        print('Invalid splithalf parameter, valid are 0,1,2.')\n",
    "        sys.exit('Fatal error in describe_returns function')\n",
    "    print('SPLITHALF CODE: ',splithalf)\n",
    "    if splithalf==0:\n",
    "        learn_returns=rtns[::]\n",
    "        test_returns=(0,)\n",
    "    else:\n",
    "        temp=int(nrows/2)\n",
    "        if splithalf==1:\n",
    "            learn_returns=rtns[:temp]\n",
    "            test_returns=rtns[temp:]\n",
    "        elif splithalf==2:\n",
    "            learn_returns=rtns[temp:]\n",
    "            test_returns=rtns[:temp]\n",
    "    return(learn_returns,test_returns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OPTIONAL METHODS FOR MODIFYING RETURN MATRIX FOR BETTER PREDICTION:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OPTIONAL MODIFICATION: ADJUST MEANS OF STOCK RETURNS TO HAVE SAME GRAND MEAN RETURNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_means(rtn_df,members,means_lookup):\n",
    "    #modify return matrix by making means equal within a secursity equivalence group\n",
    "    #subtract column means and add group mean from elements in group columns\n",
    "    for group in members:\n",
    "        if group=='NOGROUP':\n",
    "            continue\n",
    "        glist= members.get(group)\n",
    "        if glist and len(glist)>0: \n",
    "            secmeans=rtn_df[glist].mean()\n",
    "            #gmean=secmeans.mean()\n",
    "            gmean=means_lookup.get(group)/100.0\n",
    "            rtn_df[glist] += (gmean-secmeans)\n",
    "    return rtn_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DISPATCHER FOR CHOICE AMONG OPTIONAL RETURN MATRIX MODIFICATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_returns(rtn_df,mod, members,mean_lookup):  #asset classes = {'stocks': [stocklist]}   \n",
    "    if mod=='sub_means':\n",
    "        return sub_means(rtn_df,members,mean_lookup)       \n",
    "    else:\n",
    "        return rtn_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SLSQP HILL-CLIMBING OPTIMIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_init_allocate(returns_df):\n",
    "    ncols=len(returns_df.columns)\n",
    "    def_init_alloc=np.zeros(ncols,dtype='float64')\n",
    "    stdevs=np.std(returns_df,axis=0)\n",
    "    mn=np.min(stdevs)\n",
    "    idx=[i for i,v in enumerate(stdevs) if v==mn][0]\n",
    "    def_init_alloc[idx]=1.0        \n",
    "    return def_init_alloc\n",
    "\n",
    "def eqcons1(x,*args): #budget constraint\n",
    "    return(np.array([np.sum(x)-1.0]))\n",
    "\n",
    "def mobjective(x,means,covariance,risk_aversion):\n",
    "    mn=np.dot(x,means)\n",
    "    cv=np.matmul(x.T,covariance)\n",
    "    cv2=np.dot(cv,x)\n",
    "    return(-mn+risk_aversion*cv2/2.0)\n",
    "\n",
    "def wobjective2(x,levreturns,worst,leverage):\n",
    "    levportreturn=np.matmul(levreturns,x)\n",
    "    squeeze=(1.0+worst)/leverage  #for compressing over 100% losses to nearly 100%    \n",
    "    new_worst=worst+(levportreturn+1.0)*squeeze #compressing\n",
    "    safeportreturn=np.maximum(levportreturn,new_worst)     \n",
    "    log_portreturn=np.log1p(safeportreturn) #log(1+X) numpy function\n",
    "    return (-np.sum(log_portreturn))\n",
    "\n",
    "#-----------------------------------------------------------\n",
    "\n",
    "def hill_climb(returns,levs,means,covs,headers,labels,long_only,worst,ob,alloc_mat=None):\n",
    "    merit=pd.DataFrame(index=headers,columns=labels)\n",
    "    ncols2=returns.shape[1]\n",
    "    nrows2=returns.shape[0]\n",
    "    nlevs=len(levs)   \n",
    "    alloc=np.ones((nlevs,ncols2),dtype='float64')\n",
    "    prtns=np.zeros((nlevs,nrows2),dtype='float64')\n",
    "    returns_df=pd.DataFrame(returns)\n",
    "    def_init_alloc=default_init_allocate(returns_df)\n",
    "    if not long_only:\n",
    "        print('Not set up for long-short problems')\n",
    "        raise\n",
    "    #long-only bounds\n",
    "    upper=np.ones(ncols2,dtype='float64')\n",
    "    lower=np.zeros(ncols2,dtype='float64')\n",
    "    bounds=list(zip(lower,upper))\n",
    "   \n",
    "    for i in range(nlevs):     #in this use where called by cvxpy call, keep iteration over single leverage  \n",
    "        lev=levs[i]\n",
    "        levreturn=returns*lev\n",
    "        \n",
    "        if alloc_mat is None:\n",
    "            x0=default_init_allocate(returns_df)\n",
    "        else:\n",
    "            x0=alloc_mat[i]\n",
    "            \n",
    "        if ob=='MV':\n",
    "            # run mean_variance optimizer                                   \n",
    "            temp=slsqp(mobjective,x0,eqcons=[eqcons1],args=tuple((means,covs,lev)),bounds=bounds,full_output=True,acc=1e-07) \n",
    "            alloc[i]=temp[0]\n",
    "        \n",
    "        if ob=='LLS':\n",
    "            # run LLS optimizer\n",
    "            levreturns=returns*lev      \n",
    "            temp=slsqp(wobjective2,x0,eqcons=[eqcons1],args=tuple((levreturns,worst,lev)),bounds=bounds,full_output=True,acc=1e-08)\n",
    "            alloc[i]=temp[0]\n",
    "    return (None,alloc[::],None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CVXPY OPTIMIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optim_with_cvxpy2(rtns,levs,means,covs,headers,labels,long_only,worst,ob):\n",
    "    barrier=worst+1\n",
    "    merit=pd.DataFrame(index=headers,columns=labels)\n",
    "    nrows,ncols=rtns.shape\n",
    "    nlevs=len(levs)\n",
    "    mns=means.values\n",
    "    alloc=np.ones((nlevs,ncols),dtype='float64')\n",
    "    prtns=np.zeros((nlevs,nrows),dtype='float64')\n",
    "    \n",
    "    xx=cp.Variable(ncols)\n",
    "    for i in range(nlevs):\n",
    "        lev=levs[i]\n",
    "        levreturn=(rtns*lev)\n",
    "        print(' ')       \n",
    "        print(\"Risk Aversion: \",lev)\n",
    "        if ob=='MV':\n",
    "            if long_only:\n",
    "                constraints =[sum(xx)==1, 0<=xx, xx<=1] #Long-only portfolios\n",
    "            else:\n",
    "                constraints = [sum(xx)==1.0] \n",
    "            objective=cp.Minimize(-cp.sum(cp.multiply(mns,xx)) + lev*cp.quad_form(xx,covs)/2.0)\n",
    "            prob=cp.Problem(objective,constraints)\n",
    "            #result=prob.solve(verbose=True,eps_abs=1e-9,eps_rel=1e-9)\n",
    "            result=prob.solve(eps_abs=1e-7,eps_rel=1e-7)\n",
    "            xxvalue=xx.value\n",
    "            prtns[i]=np.dot(rtns,xxvalue)\n",
    "            merit['M_objective'][headers[i]]= -result\n",
    "            merit['W_objective'][headers[i]]= np.sum(np.log1p(lev*np.dot(rtns,xxvalue.T)))/nrows\n",
    "            \n",
    "        elif ob=='LLS':\n",
    "            if long_only:\n",
    "                constraints =[sum(xx)==1, 0<=xx, xx<=1, -1.0+barrier <= levreturn @ xx ] #Long-only portfolios\n",
    "            else:\n",
    "                constraints = [sum(xx)==1,-1.0+barrier <= levreturn @ xx ] #Long-short portfolios are possible \n",
    "            objective=cp.Minimize(cp.sum(-cp.log1p(levreturn@xx)))\n",
    "            prob=cp.Problem(objective,constraints)\n",
    "            result=prob.solve(abstol=1e-7,reltol=1e-7,verbose=False)/nrows\n",
    "            xxvalue=xx.value\n",
    "            if xxvalue is None:                \n",
    "                print('WARNING!!!! cvxpy problem may not be feasible.')\n",
    "                print('Using sqslp with catastrophic returns converted to less extreme losses.')\n",
    "                dummy1,wallocz,dummy2=hill_climb(rtns,[lev],means,covs,headers,labels,long_only,worst,ob,alloc_mat=None)\n",
    "                xxvalue=wallocz[0]\n",
    "                \n",
    "            prtns[i]=np.dot(rtns,xxvalue)\n",
    "            merit['M_objective'][headers[i]]= sum(means*xxvalue) - levs[i]*np.dot(np.dot(xxvalue,covs),xxvalue.T)/2.0\n",
    "            merit['W_objective'][headers[i]]= np.sum(np.log1p(np.dot(levreturn,xxvalue)))/nrows        \n",
    "        alloc[i]=xxvalue \n",
    "        merit['norm1'][headers[i]] = sum(abs(xxvalue))\n",
    "        merit['norm2'][headers[i]] = np.dot(xxvalue,xxvalue)        \n",
    "    \n",
    "    return (prtns[::].T,alloc[::],pd.DataFrame.copy(merit,deep=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CALL ALTERNATIVE ALLOCATION OPTIMIZERS AND DESCRIBE OBJECTIVE RESULTS AND DIVERSIFICATION IN-SAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_allocation(rtns_df,long_only,worst,levs):\n",
    "    #note:  think about putting try logic on an individual leverage basis rather than for whole series\n",
    "    means=np.mean(rtns_df,axis=0)\n",
    "    covs=np.cov(rtns_df.T)\n",
    "    labels=['W_objective','M_objective','norm1','norm2']\n",
    "    headers=['L:'+x for x in list(map(str,levs))]\n",
    "    rtns=rtns_df.values\n",
    "    print('RUNNING MEAN-VARIANCE OPTIMIZATION')\n",
    "    mpreturns,malloc,M_merit=optim_with_cvxpy2(rtns,levs,means,covs,headers,labels,long_only,worst,ob=\"MV\")\n",
    "\n",
    "    print(' ')\n",
    "    print('RUNNING EXPECTED SURPLUS GROWTH OPTIMIZATION')\n",
    "    wpreturns,walloc,W_merit=optim_with_cvxpy2(rtns,levs,means,covs,headers,labels,long_only,worst,ob=\"LLS\")\n",
    "    \n",
    "    print(' ')\n",
    "    print('ALLOCATIONS TO MAXIMIZE MEAN-VARIANCE')  \n",
    "    print(pd.DataFrame(np.round(malloc,5),columns=rtns_df.columns,index=headers).T)\n",
    "    print(' ')\n",
    "    print('ALLOCATIONS TO MAXIMIZE EXPECTED SURPLUS GROWTH')\n",
    "    print(pd.DataFrame(np.round(walloc,5),columns=rtns_df.columns,index=headers).T)\n",
    "    print(' ')\n",
    "    print('INCREMENTAL ALLOCATIONS')\n",
    "    dalloc=np.subtract(walloc,malloc)\n",
    "    print(pd.DataFrame(np.round(dalloc,4),columns=rtns_df.columns,index=headers).T)\n",
    "    print(' ')\n",
    "    \n",
    "    print('IN-SAMPLE ALLOCATION MERIT FROM MEAN-VARIANCE')\n",
    "    print(M_merit[['W_objective','M_objective','norm1','norm2']].head(10))\n",
    "    print(' ')    \n",
    "    print('IN-SAMPLE ALLOCATION MERIT FROM EXPECTED SURPLUS GROWTH')\n",
    "    print(W_merit[['W_objective','M_objective','norm1','norm2']].head(10))\n",
    "    print(' ')\n",
    "    print('INCREMENTAL MERIT')\n",
    "    delta_merit=np.subtract(np.array(W_merit),np.array(M_merit))\n",
    "    D_merit=pd.DataFrame(delta_merit,columns=W_merit.columns, index=W_merit.index)\n",
    "    #following necessary because np.round fails on NaN\n",
    "    with pd.option_context('display.float_format', '{:,.5f}'.format):\n",
    "        print(D_merit)\n",
    "    \n",
    "    return (wpreturns,mpreturns,walloc,malloc,W_merit,M_merit)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXTEND ALLOCATION CONSEQUENCES TO PORTFOLIO RETURN CHARACTERISTICS IN SAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_portfolio_returns(wprtns,mprtns,wmerit,mmerit,levs):\n",
    "    #COMPARE OUTPUTS ON TRADITIONAL STATISTICS\n",
    "    print(' ')\n",
    "    wpmean=pd.Series(np.mean(wprtns,axis=0))\n",
    "    wpstd=pd.Series(np.std(wprtns,axis=0))\n",
    "    wpskew=pd.Series(stats.skew(wprtns,axis=0))\n",
    "    wpkurt=pd.Series(stats.kurtosis(wprtns,axis=0,fisher=False))    \n",
    "    mpmean=pd.Series(np.mean(mprtns,axis=0))\n",
    "    mpstd=pd.Series(np.std(mprtns,axis=0))\n",
    "    mpskew=pd.Series(stats.skew(mprtns,axis=0))\n",
    "    mpkurt=pd.Series(stats.kurtosis(mprtns,axis=0,fisher=False))\n",
    "    pdescribe1=pd.DataFrame({'WMEAN': np.round(wpmean,4),'MMEAN':np.round(mpmean,4)})\n",
    "    pdescribe2=pd.DataFrame({'WSTD': np.round(wpstd,4),'MSTD':np.round(mpstd,4)})\n",
    "    pdescribe3=pd.DataFrame({'WSKEW': np.round(wpskew,3),'MSKEW':np.round(mpskew,3)})\n",
    "    pdescribe4=pd.DataFrame({'WKURT': np.round(wpkurt,3),'MKURT':np.round(mpkurt,3)})   \n",
    "    pdescribe=pd.concat([pdescribe1,pdescribe2,pdescribe3,pdescribe4],axis=1,sort=False)\n",
    "    pdescribe.index=['L:'+x for x in list(map(str,levs))]\n",
    "    print('COMPARE PORTFOLIO STATISTICS')\n",
    "    print(pdescribe)\n",
    "    \n",
    "    #X-ray on optimal in-sample surplus log growth rate objective\n",
    "    exp_utility=[x for x in wmerit['W_objective'].values]\n",
    "    xray=pd.DataFrame([levs,exp_utility,wpmean,wpstd,wpskew,wpkurt]).T\n",
    "    xray.columns=['Leverage','Exp_Log_Gr','mean','stdev','skewness','kurtosis']\n",
    "    \n",
    "    xray['Q'] = xray['Leverage']*xray['stdev']/(1+xray['Leverage']*xray['mean'])\n",
    "    print(' ')\n",
    "    headers=['L:'+x for x in list(map(str,levs))]\n",
    "    Q_df=pd.DataFrame([headers,xray['Q']]).T\n",
    "    Q_df.columns=['Leverage','Q']\n",
    "    with pd.option_context('display.float_format', '{:,.3f}'.format):\n",
    "        print(Q_df.to_string(index=False))\n",
    "    \n",
    "    xray['First']= np.log1p(xray['Leverage']*xray['mean'])\n",
    "    xray['Second']=-(xray['Q']**2)/2\n",
    "    xray['Third']=xray['skewness']*(xray['Q']**3)/3\n",
    "    xray['Fourth']=-xray['kurtosis']*(xray['Q']**4)/4\n",
    "    xray['Residual']=xray['Exp_Log_Gr']-xray['First']-xray['Second']-xray['Third']-xray['Fourth']\n",
    "    xray=xray.drop(['mean','stdev','skewness','kurtosis','Q'],axis=1)\n",
    "    print(' ')\n",
    "    print('EXPECTED SURPLUS GROWTH')\n",
    "    print('COMPOSITION BY RETURN DISTRIBUTION MOMENTS:')\n",
    "    print(' ')\n",
    "    print(xray.to_string(index=False))\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OPTIONALLY VALIDATE ALLOCATIONS ON TEST SAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merit_of_learned_allocations(learn_malloc, learn_walloc, test_returns, Llist):\n",
    "    headers=['L:'+x for x in list(map(str,Llist))]\n",
    "    labels=['W_objective','M_objective','norm1','norm2']\n",
    "    M_val_merit=pd.DataFrame(index=headers,columns=labels)\n",
    "    W_val_merit=pd.DataFrame(index=headers,columns=labels)\n",
    "    nrows=test_returns.shape[0]\n",
    "    nlevs=len(Llist)    #\n",
    "    M_val_prtns=np.zeros((nlevs,nrows),dtype='float64')\n",
    "    W_val_prtns=np.zeros((nlevs,nrows),dtype='float64')\n",
    "    test_means=np.mean(test_returns, axis=0)    \n",
    "    test_covs=np.cov(test_returns.T)\n",
    "    for ob in ['MV', 'LLS']:   \n",
    "        for i in range(nlevs):\n",
    "            if ob=='MV':\n",
    "                alloc=learn_malloc[i]\n",
    "                M_val_merit['M_objective'][headers[i]]=np.dot(alloc,test_means) - Llist[i]* np.dot(np.dot(alloc,test_covs),alloc.T)/2.0\n",
    "                M_val_merit['W_objective'][headers[i]]=np.sum(np.log1p(Llist[i]*np.dot(test_returns,alloc.T)))/nrows\n",
    "                M_val_merit['norm1'][headers[i]] = sum(abs(alloc))\n",
    "                M_val_merit['norm2'][headers[i]] = np.dot(alloc,alloc)\n",
    "                M_val_prtns[i]=np.dot(test_returns,alloc)\n",
    "            else:\n",
    "                alloc=learn_walloc[i]\n",
    "                W_val_merit['M_objective'][headers[i]]= np.dot(alloc,test_means) - Llist[i]* np.dot(np.dot(alloc,test_covs),alloc.T)/2.0\n",
    "                W_val_merit['W_objective'][headers[i]]= np.sum(np.log1p(Llist[i]*np.dot(test_returns,alloc.T)))/nrows                        \n",
    "                W_val_merit['norm1'][headers[i]] = sum(abs(alloc))\n",
    "                W_val_merit['norm2'][headers[i]] = np.dot(alloc,alloc)\n",
    "                W_val_prtns[i]=np.dot(test_returns,alloc)\n",
    "\n",
    "    return(M_val_merit,W_val_merit,M_val_prtns,W_val_prtns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OPTIONALLY PRINT VALIDATION RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_output(M_val_merit,W_val_merit,M_val_prtns,W_val_prtns,learn_M_merit,learn_W_merit,test_length,Llist):\n",
    "    print(' ')\n",
    "    print('M_val_merit')\n",
    "    print(M_val_merit)\n",
    "    print(' ')\n",
    "    print('W_val_merit')\n",
    "    print(W_val_merit)\n",
    "    print(' ')\n",
    "    print('MV OPTIMIZED MERIT CHANGES FROM LEARNING SAMPLE SOLUTION')\n",
    "    MVopt_delta_merit=np.subtract(np.array(M_val_merit),np.array(learn_M_merit))\n",
    "    MV_D_merit=pd.DataFrame(MVopt_delta_merit,columns=M_val_merit.columns, index=M_val_merit.index)\n",
    "    #following necessary because np.round fails on NaN\n",
    "    with pd.option_context('display.float_format', '{:,.5f}'.format):\n",
    "        print(MV_D_merit)\n",
    "    print(' ')\n",
    "    print('LLS OPTIMIZED MERIT CHANGES FROM LEARNING SAMPLE SOLUTION')\n",
    "    LLSopt_delta_merit=np.subtract(np.array(W_val_merit),np.array(learn_W_merit))\n",
    "    LLS_D_merit=pd.DataFrame(LLSopt_delta_merit,columns=W_val_merit.columns, index=W_val_merit.index)\n",
    "    with pd.option_context('display.float_format', '{:,.5f}'.format):\n",
    "        print(LLS_D_merit)\n",
    "    print(' ')\n",
    "\n",
    "    print('CHECK FOR LLS-OPTIMIZED RETURN LESS THAN SURPLUS')\n",
    "    print('W_val_prtns')\n",
    "    for i in range(len(W_val_prtns)):\n",
    "        print('Llist[i]: ',Llist[i])\n",
    "        for j in range(test_length):\n",
    "            if W_val_prtns[i,j]< -(1/Llist[i]):\n",
    "                print(W_val_prtns[i,j],' j: ',j)\n",
    "    print(' ')\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RESEARCH RECORDKEEPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_parameters(journalfile,logfile,sample,meanfile,codefile,sourcefile,sourcetype,Llist,splithalf,mod_method,long_only,return_interval,worst):\n",
    "    print(' ')    \n",
    "    print(f'{journalfile=}')\n",
    "    print(f'{logfile=}')\n",
    "    print(f'{sample=}')\n",
    "    print(f'{meanfile=}')\n",
    "    print(f'{codefile=}')\n",
    "    print(f'{sourcefile=}')\n",
    "    print(f'{sourcetype=}')\n",
    "    print(f'{Llist=}')\n",
    "    print(f'{splithalf=}')\n",
    "    print(f'{mod_method=}')\n",
    "    print(f'{long_only=}') \n",
    "    print(f'{return_interval=}')\n",
    "    print(f'{worst=}')\n",
    "    print(' ')\n",
    "    return\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAIN PROGRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def research_optimizer(params={}):\n",
    "\n",
    "    journalfile=params.get('journalfile')\n",
    "    logfile=params.get('logfile')\n",
    "    sample=params.get('sample')\n",
    "    meanfile=params.get('meanfile')\n",
    "    codefile=params.get('codefile')\n",
    "    sourcefile=params.get('sourcefile')\n",
    "    sourcetype=params.get('sourcetype')    \n",
    "    Llist=params.get('Llist')\n",
    "    splithalf=params.get('splithalf')\n",
    "    mod_method=params.get('mod_method')\n",
    "    long_only=params.get('long_only')\n",
    "    return_interval=params.get('return_interval')\n",
    "    worst=params.get('worst')\n",
    "        \n",
    "    #See import dependencies in first cell\n",
    "\n",
    "    #record run description in journalfile\n",
    "    orig_stdout = sys.stdout\n",
    "    e=open(journalfile, 'a')\n",
    "    sys.stdout=e\n",
    "    print_parameters(journalfile,logfile,sample,meanfile,codefile,sourcefile,sourcetype,Llist,splithalf,mod_method,long_only,return_interval,worst)\n",
    "    e.close()\n",
    "\n",
    "    #record results in logfile\n",
    "    f = open(logfile, 'w')\n",
    "    sys.stdout = f\n",
    "\n",
    "    #record control parameters\n",
    "    print_parameters(journalfile,logfile,sample,meanfile,codefile,sourcefile,sourcetype,Llist,splithalf,mod_method,long_only,return_interval,worst)\n",
    "\n",
    "    #Read asset mean returns assumed in sub-means option\n",
    "    try:\n",
    "        mean_lookup=load_asset_means(meanfile)\n",
    "        print('Means if sub_means modification used:')\n",
    "        print (mean_lookup)\n",
    "    except:\n",
    "        print('Main error: failed to load meanfile')\n",
    "        raise\n",
    "    \n",
    "    #Read in asset categories and members\n",
    "    try:\n",
    "        lookup_group,members=load_asset_codes(codefile)\n",
    "        print(' ')\n",
    "        print('Asset groups and members:')\n",
    "        print(members)\n",
    "        print(' ')\n",
    "    except:\n",
    "        print('Error: Failed to load codefile')\n",
    "        raise\n",
    "        \n",
    "    #Read in Prices or Returns, based on sourcetype, adjusted for dividends and interest if possible\n",
    "    \n",
    "    if sourcetype=='PRICES':\n",
    "        #prices=load_source(sourcefile) \n",
    "        #Rearrange prices by asset class for greater interpretability\n",
    "        prices2=rearrange(members,load_source(sourcefile) )\n",
    "        #Calculate return matrix\n",
    "        returns_df=calculate_returns(prices2,return_interval)\n",
    "    elif sourcetype=='RETURNS':\n",
    "        returns_df=rearrange(members,load_source(sourcefile))\n",
    "    else:\n",
    "        print('UNABLE TO DETERMINE SOURCE TYPE')\n",
    "        raise\n",
    "        \n",
    "    # optionally...\n",
    "    print(' ')\n",
    "    print('RETURNS SAMPLE')\n",
    "    print(returns_df.head())\n",
    "    print(' ')\n",
    "    print(returns_df.tail())\n",
    "    print(' ')\n",
    "\n",
    "    #splithalf if applied, 0: nosplit, 1:first half for learning, 2nd half for testing,\n",
    "    #   2: 2nd half for learning, first for testing\n",
    "    learn_returns,test_returns=learning_returns(returns_df.values,splithalf)\n",
    "    learn_returns_df=pd.DataFrame(learn_returns,columns=returns_df.columns)\n",
    "    print('LEARN RETURNS DESCRIPTION')\n",
    "    print(learn_returns_df.describe())\n",
    "\n",
    "    print(' ')\n",
    "    test_returns_df=None\n",
    "    if splithalf>0:\n",
    "        print(' ')\n",
    "        print('TEST RETURNS DESCRIPTION')\n",
    "        test_returns_df=pd.DataFrame(test_returns,columns=returns_df.columns)\n",
    "        print(test_returns_df.describe())\n",
    "    \n",
    "    #calculate and show moment characteristics of learn_returns\n",
    "    print(' ')\n",
    "    print('RETURN MATRIX PARAMETERS BEFORE MODIFICATION')\n",
    "    learn_means,learn_covs,learn_skews,learn_kurts,combined=rtn_summary(learn_returns,returns_df.columns)\n",
    "    print(combined.head(len(returns_df.columns)))\n",
    "    print(' ')\n",
    "\n",
    "    #May modify returns\n",
    "    if mod_method!='mirror':\n",
    "        learn_returns_df=modify_returns(learn_returns_df,mod_method,members,mean_lookup)\n",
    "        #redo description    \n",
    "        print('MODIFIED LEARN RETURNS DESCRIPTION')\n",
    "        print(learn_returns_df.describe())\n",
    "        print(' ')\n",
    "        learn_means,learn_covs,learn_skews,learn_kurts,combined=rtn_summary(learn_returns,returns_df.columns)\n",
    "        print(combined.head(len(returns_df.columns)))\n",
    "        print(' ')    \n",
    "   \n",
    "    # Do mean-variance and log leveraged surplus optimizations\n",
    "    wpreturns,mpreturns,learn_walloc,learn_malloc,learn_W_merit,learn_M_merit = find_best_allocation(\n",
    "        learn_returns_df,long_only,worst,Llist)\n",
    "\n",
    "    #describe portfolio return statistics for different leverages\n",
    "    describe_portfolio_returns(wpreturns,mpreturns,learn_W_merit,learn_M_merit,Llist)\n",
    "\n",
    "    # optionally test possibly modified learning-sample optimal allocations on test-sample\n",
    "    M_val_merit=W_val_merit=M_val_prtns=W_val_prtns=None\n",
    "    if splithalf>0:\n",
    "        M_val_merit,W_val_merit,M_val_prtns,W_val_prtns = merit_of_learned_allocations(learn_malloc, learn_walloc, test_returns, Llist = Llist)\n",
    "        test_length=len(test_returns)\n",
    "        out=validation_output(M_val_merit,W_val_merit,M_val_prtns,W_val_prtns,learn_M_merit,learn_W_merit,test_length,Llist)\n",
    "\n",
    "    #close logfile and print it on terminal\n",
    "    f.close()\n",
    "    sys.stdout = orig_stdout\n",
    "\n",
    "    h=open(logfile,'r')\n",
    "    for line in h:\n",
    "        if len(line)>0:          \n",
    "            print(line[:-1])          \n",
    "    h.close()\n",
    "        \n",
    "    optimizer_output={\n",
    "        \"params\":params,\n",
    "        \"members\":members,\n",
    "        \"learn_returns_df\":learn_returns_df,\n",
    "        \"test_returns_df\":test_returns_df,\n",
    "        \"wpreturns\":wpreturns,\n",
    "        \"mpreturns\":mpreturns,\n",
    "        \"learn_walloc\":learn_walloc,\n",
    "        \"learn_malloc\":learn_malloc,\n",
    "        \"learn_W_merit\":learn_W_merit,\n",
    "        \"learn_M_merit\":learn_M_merit,\n",
    "        \"W_val_merit\":W_val_merit,\n",
    "        \"M_val_merit\":M_val_merit,\n",
    "        \"W_val_prtns\":W_val_prtns,\n",
    "        \"M_val_prtns\":M_val_prtns,    \n",
    "    }\n",
    "    print(' ')\n",
    "    print('research_optimizer DONE!')\n",
    "    \n",
    "    return optimizer_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SET PARAMETERS AND CALL RESEARCH OPTIMIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "journalfile='JOURNAL.txt'\n",
      "logfile='RUN39.txt'\n",
      "sample='40YR'\n",
      "meanfile='CDATA40/asset_mean.csv'\n",
      "codefile='CDATA40/equiv.csv'\n",
      "sourcefile='CDATA40/prices.csv'\n",
      "sourcetype='PRICES'\n",
      "Llist=[1, 2, 4, 8, 16]\n",
      "splithalf=1\n",
      "mod_method='sub_means'\n",
      "long_only=False\n",
      "return_interval=8\n",
      "worst=-0.99\n",
      " \n",
      "Means if sub_means modification used:\n",
      "{'STOCK': 0.64, 'BOND': 0.29, 'CASH': 0.17, 'JUNK': 0.35, 'NOGROUP': nan}\n",
      " \n",
      "Asset groups and members:\n",
      "{'BOND': ['VWESX'], 'CASH': ['VWSTX'], 'JUNK': ['VWEHX'], 'STOCK': ['VFINX', 'NAESX']}\n",
      " \n",
      " \n",
      "RETURNS SAMPLE\n",
      "               VWESX     VWSTX     VWEHX     VFINX     NAESX\n",
      "Date                                                        \n",
      "1980-09-01  0.071028  0.038142  0.035762  0.125634  0.155775\n",
      "1980-10-01  0.114709  0.040574  0.074867  0.154497  0.172335\n",
      "1980-11-01  0.101957  0.039390  0.094745  0.437063  0.559259\n",
      "1980-12-01  0.011474  0.031099  0.035446  0.256342  0.269300\n",
      "1981-01-01 -0.056664  0.032828 -0.026916  0.159630  0.154481\n",
      " \n",
      "               VWESX     VWSTX     VWEHX     VFINX     NAESX\n",
      "Date                                                        \n",
      "2019-09-01  0.177752  0.015502  0.077470  0.110233  0.049510\n",
      "2019-10-01  0.180903  0.015429  0.067226  0.103920  0.019996\n",
      "2019-11-01  0.134976  0.014202  0.063513  0.128142  0.074951\n",
      "2019-12-01  0.112477  0.015224  0.060966  0.105921  0.051969\n",
      "2020-01-01  0.111286  0.013738  0.079317  0.188297  0.138257\n",
      " \n",
      "SPLITHALF CODE:  1\n",
      "LEARN RETURNS DESCRIPTION\n",
      "            VWESX       VWSTX       VWEHX       VFINX       NAESX\n",
      "count  236.000000  236.000000  236.000000  236.000000  236.000000\n",
      "mean     0.071016    0.036491    0.073720    0.107586    0.061779\n",
      "std      0.068858    0.013561    0.070098    0.119686    0.206730\n",
      "min     -0.091724    0.008025   -0.077956   -0.193951   -0.370667\n",
      "25%      0.023553    0.027432    0.025125    0.042905   -0.068461\n",
      "50%      0.074259    0.036101    0.074760    0.099161    0.083145\n",
      "75%      0.117658    0.045137    0.115392    0.189630    0.181719\n",
      "max      0.258617    0.072355    0.291650    0.437063    0.765478\n",
      " \n",
      " \n",
      "TEST RETURNS DESCRIPTION\n",
      "            VWESX       VWSTX       VWEHX       VFINX       NAESX\n",
      "count  237.000000  237.000000  237.000000  237.000000  237.000000\n",
      "mean     0.052635    0.014025    0.042460    0.048256    0.068138\n",
      "std      0.068732    0.010599    0.071986    0.130545    0.156331\n",
      "min     -0.159850   -0.001830   -0.257973   -0.411791   -0.449728\n",
      "25%      0.000893    0.005669    0.010664   -0.011598   -0.003302\n",
      "50%      0.057758    0.010863    0.041132    0.071293    0.082542\n",
      "75%      0.097991    0.020852    0.077376    0.125136    0.149401\n",
      "max      0.233603    0.045043    0.377965    0.431067    0.545292\n",
      " \n",
      "RETURN MATRIX PARAMETERS BEFORE MODIFICATION\n",
      "  TICKER    MEAN   STDEV  SKEW  KURT  VWESX  VWSTX  VWEHX  VFINX  NAESX\n",
      "0  VWESX  0.0710  0.0687 -0.09  2.65   1.00   0.71   0.80   0.33   0.29\n",
      "1  VWSTX  0.0365  0.0135  0.34  2.96   0.71   1.00   0.54   0.10   0.04\n",
      "2  VWEHX  0.0737  0.0699  0.29  2.93   0.80   0.54   1.00   0.46   0.54\n",
      "3  VFINX  0.1076  0.1194  0.02  3.15   0.33   0.10   0.46   1.00   0.80\n",
      "4  NAESX  0.0618  0.2063  0.39  3.82   0.29   0.04   0.54   0.80   1.00\n",
      " \n",
      "MODIFIED LEARN RETURNS DESCRIPTION\n",
      "            VWESX       VWSTX       VWEHX       VFINX       NAESX\n",
      "count  236.000000  236.000000  236.000000  236.000000  236.000000\n",
      "mean     0.002900    0.001700    0.003500    0.006400    0.006400\n",
      "std      0.068858    0.013561    0.070098    0.119686    0.206730\n",
      "min     -0.159840   -0.026766   -0.148176   -0.295137   -0.426046\n",
      "25%     -0.044564   -0.007360   -0.045095   -0.058281   -0.123839\n",
      "50%      0.006143    0.001310    0.004540   -0.002026    0.027766\n",
      "75%      0.049542    0.010346    0.045172    0.088444    0.126341\n",
      "max      0.190501    0.037564    0.221430    0.335876    0.710099\n",
      " \n",
      "  TICKER    MEAN   STDEV  SKEW  KURT  VWESX  VWSTX  VWEHX  VFINX  NAESX\n",
      "0  VWESX  0.0029  0.0687 -0.09  2.65   1.00   0.71   0.80   0.33   0.29\n",
      "1  VWSTX  0.0017  0.0135  0.34  2.96   0.71   1.00   0.54   0.10   0.04\n",
      "2  VWEHX  0.0035  0.0699  0.29  2.93   0.80   0.54   1.00   0.46   0.54\n",
      "3  VFINX  0.0064  0.1194  0.02  3.15   0.33   0.10   0.46   1.00   0.80\n",
      "4  NAESX  0.0064  0.2063  0.39  3.82   0.29   0.04   0.54   0.80   1.00\n",
      " \n",
      "RUNNING MEAN-VARIANCE OPTIMIZATION\n",
      " \n",
      "Risk Aversion:  1\n",
      " \n",
      "Risk Aversion:  2\n",
      " \n",
      "Risk Aversion:  4\n",
      " \n",
      "Risk Aversion:  8\n",
      " \n",
      "Risk Aversion:  16\n",
      " \n",
      "RUNNING EXPECTED SURPLUS GROWTH OPTIMIZATION\n",
      " \n",
      "Risk Aversion:  1\n",
      " \n",
      "Risk Aversion:  2\n",
      " \n",
      "Risk Aversion:  4\n",
      " \n",
      "Risk Aversion:  8\n",
      " \n",
      "Risk Aversion:  16\n",
      " \n",
      "ALLOCATIONS TO MAXIMIZE MEAN-VARIANCE\n",
      "           L:1      L:2      L:4      L:8     L:16\n",
      "VWESX -0.31020 -0.22716 -0.18565 -0.16489 -0.15451\n",
      "VWSTX  0.47505  0.80326  0.96736  1.04941  1.09043\n",
      "VWEHX  0.49577  0.24412  0.11829  0.05538  0.02392\n",
      "VFINX  0.53887  0.27462  0.14249  0.07643  0.04340\n",
      "NAESX -0.19950 -0.09483 -0.04249 -0.01632 -0.00324\n",
      " \n",
      "ALLOCATIONS TO MAXIMIZE EXPECTED SURPLUS GROWTH\n",
      "           L:1      L:2      L:4      L:8     L:16\n",
      "VWESX -0.31497 -0.23097 -0.18800 -0.16451 -0.14846\n",
      "VWSTX  0.47956  0.80327  0.96525  1.04650  1.08773\n",
      "VWEHX  0.49514  0.24740  0.12291  0.05937  0.02469\n",
      "VFINX  0.53935  0.27460  0.14127  0.07269  0.03454\n",
      "NAESX -0.19907 -0.09429 -0.04142 -0.01405  0.00150\n",
      " \n",
      "INCREMENTAL ALLOCATIONS\n",
      "          L:1     L:2     L:4     L:8    L:16\n",
      "VWESX -0.0048 -0.0038 -0.0024  0.0004  0.0060\n",
      "VWSTX  0.0045  0.0000 -0.0021 -0.0029 -0.0027\n",
      "VWEHX -0.0006  0.0033  0.0046  0.0040  0.0008\n",
      "VFINX  0.0005 -0.0000 -0.0012 -0.0037 -0.0089\n",
      "NAESX  0.0004  0.0005  0.0011  0.0023  0.0047\n",
      " \n",
      "IN-SAMPLE ALLOCATION MERIT FROM MEAN-VARIANCE\n",
      "     W_objective  M_objective    norm1     norm2\n",
      "L:1    0.0026565   0.00265636   2.0194  0.897878\n",
      "L:2   0.00409936   0.00204921  1.64399  0.840826\n",
      "L:4   0.00664811   0.00166243  1.45628   1.00635\n",
      "L:8     0.010422   0.00130263  1.36243   1.13762\n",
      "L:16   0.0127334  0.000789907   1.3155   1.21538\n",
      " \n",
      "IN-SAMPLE ALLOCATION MERIT FROM EXPECTED SURPLUS GROWTH\n",
      "     W_objective  M_objective    norm1     norm2\n",
      "L:1   0.00265655   0.00265632  2.02809  0.904873\n",
      "L:2   0.00409945   0.00204916  1.65053  0.844087\n",
      "L:4    0.0066488   0.00166225  1.45886   1.00382\n",
      "L:8    0.0104276   0.00130187  1.35712   1.13123\n",
      "L:16   0.0128008  0.000785472  1.29692     1.207\n",
      " \n",
      "INCREMENTAL MERIT\n",
      "     W_objective M_objective    norm1    norm2\n",
      "L:1      0.00000    -0.00000  0.00869  0.00700\n",
      "L:2      0.00000    -0.00000  0.00654  0.00326\n",
      "L:4      0.00000    -0.00000  0.00258 -0.00252\n",
      "L:8      0.00001    -0.00000 -0.00531 -0.00639\n",
      "L:16     0.00007    -0.00000 -0.01858 -0.00838\n",
      " \n",
      "COMPARE PORTFOLIO STATISTICS\n",
      "       WMEAN   MMEAN    WSTD    MSTD  WSKEW  MSKEW  WKURT  MKURT\n",
      "L:1   0.0038  0.0038  0.0480  0.0480 -0.072 -0.075  2.671  2.662\n",
      "L:2   0.0027  0.0027  0.0258  0.0257  0.018  0.014  2.822  2.816\n",
      "L:4   0.0022  0.0022  0.0158  0.0157  0.076  0.060  3.034  3.018\n",
      "L:8   0.0019  0.0019  0.0120  0.0120  0.094  0.051  2.836  2.785\n",
      "L:16  0.0017  0.0017  0.0109  0.0109  0.157  0.075  2.464  2.408\n",
      " \n",
      "Leverage     Q\n",
      "     L:1 0.048\n",
      "     L:2 0.051\n",
      "     L:4 0.063\n",
      "     L:8 0.095\n",
      "    L:16 0.169\n",
      " \n",
      "EXPECTED SURPLUS GROWTH\n",
      "COMPOSITION BY RETURN DISTRIBUTION MOMENTS:\n",
      " \n",
      " Leverage  Exp_Log_Gr     First    Second         Third    Fourth      Residual\n",
      "      1.0    0.002657  0.003805 -0.001143 -2.622594e-06 -0.000003 -4.126013e-08\n",
      "      2.0    0.004099  0.005416 -0.001313  7.911677e-07 -0.000005 -5.380228e-08\n",
      "      4.0    0.006649  0.008622 -0.001968  6.250379e-06 -0.000012 -1.483528e-07\n",
      "      8.0    0.010428  0.014968 -0.004509  2.679497e-05 -0.000058 -6.965870e-07\n",
      "     16.0    0.012801  0.027392 -0.014332  2.544926e-04 -0.000506 -7.976838e-06\n",
      " \n",
      "M_val_merit\n",
      "     W_objective M_objective    norm1     norm2\n",
      "L:1    0.0213939   0.0216575   2.0194  0.897878\n",
      "L:2    0.0305063   0.0154844  1.64399  0.840826\n",
      "L:4    0.0479927   0.0122717  1.45628   1.00635\n",
      "L:8    0.0803038    0.010413  1.36243   1.13762\n",
      "L:16    0.136031  0.00897891   1.3155   1.21538\n",
      " \n",
      "W_val_merit\n",
      "     W_objective M_objective    norm1     norm2\n",
      "L:1    0.0212321   0.0214925  2.02809  0.904873\n",
      "L:2    0.0304258   0.0154431  1.65053  0.844087\n",
      "L:4    0.0481511   0.0123128  1.45886   1.00382\n",
      "L:8     0.081205   0.0105346  1.35712   1.13123\n",
      "L:16    0.139278  0.00920786  1.29692     1.207\n",
      " \n",
      "MV OPTIMIZED MERIT CHANGES FROM LEARNING SAMPLE SOLUTION\n",
      "     W_objective M_objective   norm1   norm2\n",
      "L:1      0.01874     0.01900 0.00000 0.00000\n",
      "L:2      0.02641     0.01344 0.00000 0.00000\n",
      "L:4      0.04134     0.01061 0.00000 0.00000\n",
      "L:8      0.06988     0.00911 0.00000 0.00000\n",
      "L:16     0.12330     0.00819 0.00000 0.00000\n",
      " \n",
      "LLS OPTIMIZED MERIT CHANGES FROM LEARNING SAMPLE SOLUTION\n",
      "     W_objective M_objective   norm1   norm2\n",
      "L:1      0.01858     0.01884 0.00000 0.00000\n",
      "L:2      0.02633     0.01339 0.00000 0.00000\n",
      "L:4      0.04150     0.01065 0.00000 0.00000\n",
      "L:8      0.07078     0.00923 0.00000 0.00000\n",
      "L:16     0.12648     0.00842 0.00000 0.00000\n",
      " \n",
      "CHECK FOR LLS-OPTIMIZED RETURN LESS THAN SURPLUS\n",
      "W_val_prtns\n",
      "Llist[i]:  1\n",
      "Llist[i]:  2\n",
      "Llist[i]:  4\n",
      "Llist[i]:  8\n",
      "Llist[i]:  16\n",
      " \n",
      " \n",
      "research_optimizer DONE!\n"
     ]
    }
   ],
   "source": [
    "#set parameters\n",
    "\n",
    "params=dict(\n",
    "    journalfile='JOURNAL.txt',\n",
    "    logfile='RUN39.txt',\n",
    "    sample='40YR',\n",
    "    meanfile='CDATA40/asset_mean.csv',\n",
    "    codefile='CDATA40/equiv.csv',\n",
    "    sourcefile='CDATA40/prices.csv',\n",
    "    sourcetype='PRICES',\n",
    "    Llist=[1,2,4,8,16],\n",
    "    splithalf=1,\n",
    "    mod_method='sub_means',\n",
    "    long_only=False,\n",
    "    return_interval=8,\n",
    "    worst=(-0.99),\n",
    "    )\n",
    "#run main program\n",
    "optimizer_output=research_optimizer(params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRAPHICS PROGRAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_compare(sample1,sample2):\n",
    "    #we create two subplots sharing the same y axis.\n",
    "    f, (ax1, ax2)= plt.subplots(1,2,figsize=(12,5),sharey=True,sharex=True)\n",
    "    \n",
    "    #Left subplot.\n",
    "    #Histogram and KDE (active by default).\n",
    "    sns.distplot(sample1, ax=ax1, hist=True, rug=True)\n",
    "    \n",
    "    #Right subplot.\n",
    "    # \"Rugplot\", KDE and gamma fit.\n",
    "    sns.distplot(sample2, ax=ax2, hist=True, kde=True,\n",
    "                rug=True,\n",
    "                 kde_kws=dict(label='kde'))\n",
    "    ax2.legend()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DISPLAY GRAPHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "out=optimizer_output\n",
    "splithalf=out['params']['splithalf']\n",
    "if splithalf==0:\n",
    "    histogram_compare(out['learn_returns_df']['VFINX'],out['learn_returns_df']['VWEHX'])\n",
    "elif splithalf>0:\n",
    "    histogram_compare(out['learn_returns_df']['VFINX'],out['test_returns_df']['VFINX'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
