{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "Notebook name: Higher Moments\n",
    "Author: Jarrod Wilcox\n",
    "Version: 0.3.0\n",
    "Date: 7/13/2020\n",
    "Contact:  jarrod@wealthmate.com\n",
    "\n",
    "higher_moments is a basic research program to read a clean file, fully-populated, of prices adjusted for any distributions, or alternatively, a return file, and then to produce portfolio allocations with analytics comparing best allocations from scenario-based probability distributions of expected ln(1+Lr), or Rubinstein, utility with those from Markowitz's mean-variance approach.\n",
    "\n",
    "Distributed as is, with MIT license, suitable only for education and research.\n",
    "\n",
    "Oldest installable dependencies tested:  python 3.8.3, numpy 1.15.4, scipy 1.4.1, pandas 1.03, \n",
    "jupyter 1.0.0, cvxpy 1.1.1.\n",
    "\n",
    "SAMPLE INPUTS:\n",
    "journalfile='JOURNAL.txt'\n",
    "logfile='RUN39.txt'\n",
    "sample='40YR'\n",
    "meanfile='CDATA40/asset_mean.csv'\n",
    "codefile='CDATA40/equiv.csv'\n",
    "sourcefile='CDATA40/prices.csv'\n",
    "sourcetype='PRICES'\n",
    "Llist=[1, 2, 4, 8, 16]\n",
    "splithalf=1\n",
    "mod_method='sub_means'\n",
    "long_only=False\n",
    "return_interval=8\n",
    "worst=-0.99\n",
    "\n",
    "journalfile: a file to append a list of run input descriptors to be used as a directory for various optimization runs\n",
    "\n",
    "logfile: a file that mirrors the printed program output for this set of inputs\n",
    "\n",
    "sample: arbitrary text describing the run to jog the researcher's memory\n",
    "\n",
    "meanfile: file containing estimated mean returns per period for any securities where a priori \n",
    "estimated returns are to have a designated mean applied to all member securities within an asset group\n",
    "\n",
    "codefile: a path to a csv file containing two columns, security tickers or other ids and\n",
    "    their asset categories  or \"NOGROUPS\"\n",
    "\n",
    "sourcefile: a path to a csv price or return file (sorted by oldest-first, regular dates and adjusted for dividends and interest) with column headers identifying the security (usually a ticker), with the left-most column 'Date'\n",
    "\n",
    "sourcetype:  designation of whether the return source is in terms of prices or returns.\n",
    "    \n",
    "Llist: a vector of risk aversion coefficients, with larger numbers representing more conservatism.\n",
    "\n",
    "splithalf: 0,1,or 2, with 0 signifying use whole sample, 1 to use first half to learn, and last half to test,\n",
    "    and 2 vice versa.\n",
    "\n",
    "mod_method:  In this version, use either 'mirror', to give no return modification, or 'sub_means', causing the program to modify returns to induce all members of a group  to have the same mean return within the learning sample.  Alternatively, the researcher may write their own function to modify or add rows to the return matrix.\n",
    "\n",
    "long_only: True induces allocation constraints insuring all allocations lie on the interval 0,1. False allows long-short funds (recommended only for research)!\n",
    "\n",
    "return_interval: Returns are calculated by a comparison of current price and the price from regular_interval rows older.\n",
    "\n",
    "worst= -0.99:  If no feasible solution exists, a \"best efforts\" solution is presented, along with a message than no solution can meet the constraints.  Stock-only portfolios for conservative investors will not be feasible for very conservative investors.\n",
    "\n",
    "Sample data files are included in the repository.\n",
    "\n",
    "\n",
    "EXPECTED OUTPUT:\n",
    "Produces screen output, a logfile with a printout of program input and results, and appends its input\n",
    "    descriptions to a journal file.\n",
    "\n",
    "An article \"Better Portfolios with Higher Moments\" by Jarrod Wilcox, Journal of Asset Management 2020, provides further details on the approach.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEPENDENCIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import fmin_slsqp as slsqp\n",
    "from datetime import datetime\n",
    "from math import exp, isnan\n",
    "try:\n",
    "    import cvxpy as cp    \n",
    "except:\n",
    "    print ('This version of higher_moments requires installation of cvxpy.')\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GET PRIOR ASSET RETURN MEANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_asset_means(meanfile=None):\n",
    "    try:\n",
    "        ameans=pd.read_csv(meanfile).values\n",
    "        means_lookup={row[0]:row[1] for row in ameans}\n",
    "        return(means_lookup)\n",
    "    except:\n",
    "        print('NO ASSET MEANS FOUND')\n",
    "        raise\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GET ASSET GROUP CATEGORIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get asset group codes\n",
    "def load_asset_codes(codefile=None):\n",
    "    try:\n",
    "        equivs=pd.read_csv(codefile).values\n",
    "        equivs=[x if isinstance(x[1],str) else [x[0],'NOGROUP'] for x in equivs]\n",
    "        lookup_group={}\n",
    "        for tick in equivs:\n",
    "            lookup_group[tick[0]]=tick[1]\n",
    "        members={}\n",
    "        categories=sorted(set([x[1] for x in equivs]))\n",
    "        for group in categories:\n",
    "            members[group]=[x[0] for x in equivs if x[1]==group]     \n",
    "        return(lookup_group,members)\n",
    "    except:\n",
    "        print('NO ASSET CATEGORIZATION FOUND')\n",
    "        raise\n",
    "\n",
    "#a,b=load_asset_codes('CDATA40/equiv.csv')\n",
    "#print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD INPUT PRICE FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_source(sourcefile):\n",
    "    try:\n",
    "        source=pd.read_csv(sourcefile)\n",
    "        temp=source.get('Date')\n",
    "        if not temp is None:\n",
    "            source.index=temp \n",
    "            source=source.drop(columns=['Date'])\n",
    "        return source\n",
    "    except:\n",
    "        print('NO SOURCE FOUND')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REARRANGE COLUMNS BY ASSET CLASS IF SOURCE IS RETURN FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def rearrange(members,source):\n",
    "    cols=[tick for group in members for tick in members[group]]\n",
    "    source2=pd.DataFrame(columns=cols,index=source.index)\n",
    "    for tick in cols:\n",
    "        source2[tick]=source[tick]\n",
    "    return(source2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CALCULATE RETURNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_returns(prices2,return_interval):\n",
    "    price_data=np.array(prices2.values,dtype='float32')\n",
    "    price_data1=np.ones((price_data.shape[0],price_data.shape[1]))\n",
    "    price_data1[return_interval:]=price_data[:-return_interval]\n",
    "    returns=(price_data/price_data1)\n",
    "    returns=returns[return_interval:]-1. \n",
    "    returns_df=pd.DataFrame(returns)   \n",
    "    returns_df.columns=prices2.columns\n",
    "    returns_df.index=prices2.index[return_interval:]\n",
    "    return(returns_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COLLECT FURTHER STATISTICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rtn_summary(returns,tickers):\n",
    "    means=np.mean(returns,axis=0) \n",
    "    covs=np.cov(returns.T)\n",
    "    stdevs=np.std(returns,axis=0)\n",
    "    corrs=np.round_(np.corrcoef(returns.T),2)\n",
    "    corr=pd.DataFrame(corrs,columns=tickers)\n",
    "    means=pd.Series(means)\n",
    "    stdev=pd.Series(stdevs)\n",
    "    skews=stats.skew(returns,axis=0)\n",
    "    skew=pd.Series(skews)\n",
    "    kurts=stats.kurtosis(returns,axis=0,fisher=False)\n",
    "    kurt=pd.Series(kurts)\n",
    "    descript=pd.DataFrame({'TICKER':tickers,'MEAN':np.round(means,4),\n",
    "        'STDEV':np.round(stdev,4),'SKEW':np.round(skew,2),'KURT':np.round(kurt,2)})\n",
    "    combined=descript.join(corr,how='outer')      \n",
    "        \n",
    "    return (means,covs,skews,kurts,combined)\n",
    "#means,covs,skews,kurts=rtn_summary(returns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OPTIONALLY SPLIT SAMPLE INTO SMALLER LEARN AND VALIDATE SUBSAMPLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  learning_returns(rtns,splithalf=0):\n",
    "    #rtns is np array, not dataframe\n",
    "    nrows = rtns.shape[0]\n",
    "    #set up split sample if desired\n",
    "    if splithalf not in [0,1,2]:\n",
    "        print('Invalid splithalf parameter, valid are 0,1,2.')\n",
    "        sys.exit('Fatal error in describe_returns function')\n",
    "    print('SPLITHALF CODE: ',splithalf)\n",
    "    if splithalf==0:\n",
    "        learn_returns=rtns[::]\n",
    "        test_returns=(0,)\n",
    "    else:\n",
    "        temp=int(nrows/2)\n",
    "        if splithalf==1:\n",
    "            learn_returns=rtns[:temp]\n",
    "            test_returns=rtns[temp:]\n",
    "        elif splithalf==2:\n",
    "            learn_returns=rtns[temp:]\n",
    "            test_returns=rtns[:temp]\n",
    "    return(learn_returns,test_returns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OPTIONAL METHODS FOR MODIFYING RETURN MATRIX FOR BETTER PREDICTION:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OPTIONAL MODIFICATION: ADJUST MEANS OF STOCK RETURNS TO HAVE SAME GRAND STOCK MEAN RETURN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_means(rtn_df,members,means_lookup):\n",
    "    #modify return matrix by making means equal within a secursity equivalence group\n",
    "    # modifies other parameters because of change in means\n",
    "    #subtract column means and add group mean from elements in group columns\n",
    "    for group in members:\n",
    "        if group=='NOGROUP':\n",
    "            continue\n",
    "        glist= members.get(group)\n",
    "        if glist and len(glist)>0: \n",
    "            secmeans=rtn_df[glist].mean()\n",
    "            #gmean=secmeans.mean()\n",
    "            gmean=means_lookup.get(group)/100.0\n",
    "            rtn_df[glist] += (gmean-secmeans)\n",
    "    return rtn_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DISPATCHER FOR CHOICE AMONG OPTIONAL RETURN MATRIX MODIFICATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_returns(rtn_df,mod, members,mean_lookup):  #asset classes = {'stocks': [stocklist]}   \n",
    "    if mod=='sub_means':\n",
    "        return sub_means(rtn_df,members,mean_lookup)       \n",
    "    else:\n",
    "        return rtn_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SLSQP HILL-CLIMBING OPTIMIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_init_allocate(returns_df):\n",
    "    ncols=len(returns_df.columns)\n",
    "    def_init_alloc=np.zeros(ncols,dtype='float64')\n",
    "    stdevs=np.std(returns_df,axis=0)\n",
    "    mn=np.min(stdevs)\n",
    "    idx=[i for i,v in enumerate(stdevs) if v==mn][0]\n",
    "    def_init_alloc[idx]=1.0        \n",
    "    return def_init_alloc\n",
    "\n",
    "def eqcons1(x,*args): #budget constraint\n",
    "    return(np.array([np.sum(x)-1.0]))\n",
    "\n",
    "def mobjective(x,means,covariance,risk_aversion):\n",
    "    mn=np.dot(x,means)\n",
    "    cv=np.matmul(x.T,covariance)\n",
    "    cv2=np.dot(cv,x)\n",
    "    return(-mn+risk_aversion*cv2/2.0)\n",
    "\n",
    "def wobjective2(x,levreturns,worst,leverage):\n",
    "    levportreturn=np.matmul(levreturns,x)\n",
    "    squeeze=(1.0+worst)/leverage  #for compressing over 100% losses to nearly 100%    \n",
    "    new_worst=worst+(levportreturn+1.0)*squeeze #compressing\n",
    "    safeportreturn=np.maximum(levportreturn,new_worst)     \n",
    "    log_portreturn=np.log1p(safeportreturn) #log(1+X) numpy function\n",
    "    return (-np.sum(log_portreturn))\n",
    "\n",
    "#-----------------------------------------------------------\n",
    "\n",
    "def hill_climb(returns,levs,means,covs,headers,labels,long_only,worst,ob,alloc_mat=None):\n",
    "    merit=pd.DataFrame(index=headers,columns=labels)\n",
    "    ncols2=returns.shape[1]\n",
    "    nrows2=returns.shape[0]\n",
    "    nlevs=len(levs)   \n",
    "    alloc=np.ones((nlevs,ncols2),dtype='float64')\n",
    "    prtns=np.zeros((nlevs,nrows2),dtype='float64')\n",
    "    returns_df=pd.DataFrame(returns)\n",
    "    def_init_alloc=default_init_allocate(returns_df)\n",
    "    if not long_only:\n",
    "        print('Not set up for long-short problems')\n",
    "        raise\n",
    "    #long-only bounds\n",
    "    upper=np.ones(ncols2,dtype='float64')\n",
    "    lower=np.zeros(ncols2,dtype='float64')\n",
    "    bounds=list(zip(lower,upper))\n",
    "   \n",
    "    for i in range(nlevs):     #in this use where called by cvxpy call, keep iteration over single leverage  \n",
    "        lev=levs[i]\n",
    "        levreturn=returns*lev\n",
    "        \n",
    "        if alloc_mat is None:\n",
    "            x0=default_init_allocate(returns_df)\n",
    "        else:\n",
    "            x0=alloc_mat[i]\n",
    "            \n",
    "        if ob=='MV':\n",
    "            # run mean_variance optimizer                                   \n",
    "            temp=slsqp(mobjective,x0,eqcons=[eqcons1],args=tuple((means,covs,lev)),bounds=bounds,full_output=True,acc=1e-07) \n",
    "            alloc[i]=temp[0]\n",
    "        \n",
    "        if ob=='LLS':\n",
    "            # run LLS optimizer\n",
    "            levreturns=returns*lev      \n",
    "            temp=slsqp(wobjective2,x0,eqcons=[eqcons1],args=tuple((levreturns,worst,lev)),bounds=bounds,full_output=True,acc=1e-08)\n",
    "            alloc[i]=temp[0]\n",
    "    return (None,alloc[::],None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CVXPY OPTIMIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optim_with_cvxpy2(orig_rtns,mrtns,levs,mmeans,mcovs,headers,labels,long_only,worst,ob):\n",
    "    barrier=worst+1\n",
    "    merit=pd.DataFrame(index=headers,columns=labels)\n",
    "    nrows,ncols=mrtns.shape\n",
    "    nlevs=len(levs)\n",
    "    mns=mmeans.values\n",
    "    orig_means=np.mean(orig_rtns,axis=0)\n",
    "    orig_covs=np.cov(orig_rtns.T)\n",
    "    alloc=np.ones((nlevs,ncols),dtype='float64')\n",
    "    prtns=np.zeros((nlevs,nrows),dtype='float64')\n",
    "    \n",
    "    xx=cp.Variable(ncols)\n",
    "    for i in range(nlevs):\n",
    "        lev=levs[i]\n",
    "        mlevreturn=(mrtns*lev)\n",
    "        orig_levreturn=(orig_rtns*lev)\n",
    "        #print(' ')       \n",
    "        print(\"Risk Aversion: \",lev)\n",
    "        if ob=='MV':\n",
    "            if long_only:\n",
    "                constraints =[sum(xx)==1, 0<=xx, xx<=1] #Long-only portfolios\n",
    "            else:\n",
    "                constraints = [sum(xx)==1.0] \n",
    "            objective=cp.Minimize(-cp.sum(cp.multiply(mns,xx)) + lev*cp.quad_form(xx,mcovs)/2.0)\n",
    "            prob=cp.Problem(objective,constraints)\n",
    "            #result=prob.solve(verbose=True,eps_abs=1e-9,eps_rel=1e-9)\n",
    "            result=prob.solve(eps_abs=1e-7,eps_rel=1e-7)\n",
    "            xxvalue=xx.value\n",
    "            prtns[i]=np.dot(orig_rtns,xxvalue)\n",
    "            merit['M_objective'][headers[i]]= np.sum(orig_means*xxvalue) - levs[i]*np.dot(np.dot(xxvalue,orig_covs),xxvalue.T)/2.0\n",
    "            merit['W_objective'][headers[i]]= np.sum(np.log1p(lev*np.dot(orig_rtns,xxvalue.T)))/nrows\n",
    "            \n",
    "        elif ob=='LLS':\n",
    "            if long_only:\n",
    "                constraints =[sum(xx)==1, 0<=xx, xx<=1, -1.0+barrier <= mlevreturn @ xx ] #Long-only portfolios\n",
    "            else:\n",
    "                constraints = [sum(xx)==1,-1.0+barrier <= mlevreturn @ xx ]\n",
    "            objective=cp.Minimize(cp.sum(-cp.log1p(mlevreturn@xx)))\n",
    "            prob=cp.Problem(objective,constraints)\n",
    "            result=prob.solve(abstol=1e-7,reltol=1e-7,verbose=False)/nrows\n",
    "            xxvalue=xx.value\n",
    "            if xxvalue is None:                \n",
    "                print('WARNING!!!! cvxpy problem may not be feasible.')\n",
    "                print('Using sqslp with catastrophic returns converted to less extreme losses.')\n",
    "                dummy1,wallocz,dummy2=hill_climb(mrtns,[lev],mmeans,mcovs,headers,labels,long_only,worst,ob,alloc_mat=None)\n",
    "                xxvalue=wallocz[0]\n",
    "                \n",
    "            prtns[i]=np.dot(orig_rtns,xxvalue)\n",
    "            merit['M_objective'][headers[i]]= sum(orig_means*xxvalue) - levs[i]*np.dot(np.dot(xxvalue,orig_covs),xxvalue.T)/2.0\n",
    "            merit['W_objective'][headers[i]]= np.sum(np.log1p(np.dot(orig_levreturn,xxvalue)))/nrows        \n",
    "        alloc[i]=xxvalue        \n",
    "    \n",
    "    return (prtns[::].T,alloc[::],pd.DataFrame.copy(merit,deep=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CALL ALTERNATIVE ALLOCATION OPTIMIZERS AND DESCRIBE OBJECTIVE RESULTS AND DIVERSIFICATION IN-SAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_allocation(rtns_df,mrtns_df,long_only,worst,levs,lookup_group=None):\n",
    "    rtns=rtns_df.values\n",
    "    mrtns=mrtns_df.values\n",
    "    rtns_cols=rtns_df.columns\n",
    "    means=np.mean(rtns_df,axis=0)\n",
    "    mmeans=np.mean(mrtns_df,axis=0)\n",
    "    covs=np.cov(rtns_df.T)\n",
    "    mcovs=np.cov(mrtns_df.T)\n",
    "    headers=['L:'+x for x in list(map(str,levs))]\n",
    "    labels=['W_objective','M_objective']\n",
    "    \n",
    "    print('RUNNING MEAN-VARIANCE OPTIMIZATION')\n",
    "    mpreturns,malloc,M_merit=optim_with_cvxpy2(rtns,mrtns,levs,mmeans,mcovs,headers,labels,long_only,worst,ob=\"MV\")\n",
    "    print(' ')\n",
    "    print('RUNNING EXPECTED SURPLUS GROWTH OPTIMIZATION')\n",
    "    wpreturns,walloc,W_merit=optim_with_cvxpy2(rtns,mrtns,levs,mmeans,mcovs,headers,labels,long_only,worst,ob=\"LLS\")\n",
    "    \n",
    "    print(' ')\n",
    "    print('ALLOCATIONS TO MAXIMIZE MEAN-VARIANCE')  \n",
    "    print(pd.DataFrame(np.round(malloc,5),columns=rtns_df.columns,index=headers).T)\n",
    "    print(' ')\n",
    "    print('ALLOCATIONS TO MAXIMIZE EXPECTED SURPLUS GROWTH')\n",
    "    print(pd.DataFrame(np.round(walloc,5),columns=rtns_df.columns,index=headers).T)\n",
    "    print(' ')\n",
    "    print('INCREMENTAL ALLOCATIONS')\n",
    "    dalloc=np.subtract(walloc,malloc)\n",
    "    print(pd.DataFrame(np.round(dalloc,4),columns=rtns_df.columns,index=headers).T)\n",
    "    print(' ')\n",
    "    print('IN-SAMPLE ALLOCATION MERIT FROM MEAN-VARIANCE')\n",
    "    print(M_merit[['W_objective','M_objective']].head(10))\n",
    "    print(' ')    \n",
    "    print('IN-SAMPLE ALLOCATION MERIT FROM EXPECTED SURPLUS GROWTH')\n",
    "    print(W_merit[['W_objective','M_objective']].head(10))\n",
    "    print(' ')\n",
    "    print('INCREMENTAL MERIT')\n",
    "    delta_merit=np.subtract(np.array(W_merit),np.array(M_merit))\n",
    "    D_merit=pd.DataFrame(delta_merit,columns=W_merit.columns, index=W_merit.index)\n",
    "    #following necessary because np.round fails on NaN\n",
    "    with pd.option_context('display.float_format', '{:,.5f}'.format):\n",
    "        print(D_merit)\n",
    "    \n",
    "    return (wpreturns,mpreturns,walloc,malloc,W_merit,M_merit)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXTEND ALLOCATION CONSEQUENCES TO PORTFOLIO RETURN CHARACTERISTICS IN SAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_xray(merit,objective,levs,pmean,pstd,pskew,pkurt):\n",
    "    #X-ray on optimal in-sample surplus log growth rate objective\n",
    "    exp_utility=[x for x in merit[objective].values]\n",
    "    xray=pd.DataFrame([levs,exp_utility,pmean,pstd,pskew,pkurt]).T\n",
    "    xray.columns=['Leverage','Exp_Log_Gr','mean','stdev','skewness','kurtosis']\n",
    "    \n",
    "    xray['Q'] = xray['Leverage']*xray['stdev']/(1+xray['Leverage']*xray['mean'])\n",
    "    print(' ')\n",
    "    headers=['L:'+x for x in list(map(str,levs))]\n",
    "    Q_df=pd.DataFrame([headers,xray['Q']]).T\n",
    "    Q_df.columns=['Leverage','Q']\n",
    "    with pd.option_context('display.float_format', '{:,.3f}'.format):\n",
    "        print(Q_df.to_string(index=False))\n",
    "    \n",
    "    xray['First']= np.log1p(xray['Leverage']*xray['mean'])\n",
    "    xray['Second']=-(xray['Q']**2)/2\n",
    "    xray['Third']=xray['skewness']*(xray['Q']**3)/3\n",
    "    xray['Fourth']=-xray['kurtosis']*(xray['Q']**4)/4\n",
    "    xray['Residual']=xray['Exp_Log_Gr']-xray['First']-xray['Second']-xray['Third']-xray['Fourth']\n",
    "    xray=xray.drop(['mean','stdev','skewness','kurtosis','Q'],axis=1)\n",
    "    print(' ')\n",
    "    \n",
    "    print('COMPOSITION BY RETURN DISTRIBUTION MOMENTS:')\n",
    "    print(' ')\n",
    "    print(xray.to_string(index=False))    \n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_portfolio_returns(wprtns,mprtns,wmerit,mmerit,levs):\n",
    "    #COMPARE OUTPUTS ON TRADITIONAL STATISTICS\n",
    "    print(' ')\n",
    "    \n",
    "    wpmean=pd.Series(np.mean(wprtns,axis=0))\n",
    "    wpstd=pd.Series(np.std(wprtns,axis=0))\n",
    "    wpskew=pd.Series(stats.skew(wprtns,axis=0))\n",
    "    wpkurt=pd.Series(stats.kurtosis(wprtns,axis=0,fisher=False))    \n",
    "\n",
    "    mpmean=pd.Series(np.mean(mprtns,axis=0))\n",
    "    mpstd=pd.Series(np.std(mprtns,axis=0))\n",
    "    mpskew=pd.Series(stats.skew(mprtns,axis=0))\n",
    "    mpkurt=pd.Series(stats.kurtosis(mprtns,axis=0,fisher=False))\n",
    "    \n",
    "    pdescribe1=pd.DataFrame({'WMEAN': np.round(wpmean,4),'MMEAN':np.round(mpmean,4)})\n",
    "    pdescribe2=pd.DataFrame({'WSTD': np.round(wpstd,4),'MSTD':np.round(mpstd,4)})\n",
    "    pdescribe3=pd.DataFrame({'WSKEW': np.round(wpskew,3),'MSKEW':np.round(mpskew,3)})\n",
    "    pdescribe4=pd.DataFrame({'WKURT': np.round(wpkurt,3),'MKURT':np.round(mpkurt,3)})   \n",
    "    pdescribe=pd.concat([pdescribe1,pdescribe2,pdescribe3,pdescribe4],axis=1,sort=False)\n",
    "    pdescribe.index=['L:'+x for x in list(map(str,levs))]\n",
    "    print('COMPARE PORTFOLIO STATISTICS')\n",
    "\n",
    "    print(' ')\n",
    "    print('IN_SAMPLE SURPLUS GROWTH OBJECTIVE WITH MEAN-VARIANCE OPTIMIZATION')\n",
    "    show_xray(mmerit,'W_objective',levs,mpmean,mpstd,mpskew,mpkurt)\n",
    "    print(' ')\n",
    "    print('IN-SAMPLE SURPLUS GROWTH OBJECTIVE WITH SURPLUS GROWTH OPTIMIZATION')\n",
    "    show_xray(wmerit,'W_objective',levs,wpmean,wpstd,wpskew,wpkurt)\n",
    "    print(' ')\n",
    "\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OPTIONALLY VALIDATE ALLOCATIONS ON TEST SAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merit_of_learned_allocations(learn_malloc, learn_walloc, test_returns, Llist):\n",
    "    headers=['L:'+x for x in list(map(str,Llist))]\n",
    "    labels=['W_objective','M_objective']\n",
    "    M_val_merit=pd.DataFrame(index=headers,columns=labels)\n",
    "    W_val_merit=pd.DataFrame(index=headers,columns=labels)\n",
    "    nrows=test_returns.shape[0]\n",
    "    nlevs=len(Llist)\n",
    "    M_val_prtns=np.zeros((nlevs,nrows),dtype='float64')\n",
    "    W_val_prtns=np.zeros((nlevs,nrows),dtype='float64')\n",
    "    test_means=np.mean(test_returns, axis=0)    \n",
    "    test_covs=np.cov(test_returns.T)\n",
    "            \n",
    "    for ob in ['MV', 'LLS']:   \n",
    "        for i in range(nlevs):\n",
    "            if ob=='MV':\n",
    "                alloc=learn_malloc[i]\n",
    "                M_val_merit['M_objective'][headers[i]]=np.dot(alloc,test_means) - Llist[i]* np.dot(np.dot(alloc,test_covs),alloc.T)/2.0\n",
    "                M_val_merit['W_objective'][headers[i]]=np.sum(np.log1p(Llist[i]*np.dot(test_returns,alloc.T)))/nrows\n",
    "                M_val_prtns[i]=np.dot(test_returns,alloc)\n",
    "            else:\n",
    "                alloc=learn_walloc[i]\n",
    "                W_val_merit['M_objective'][headers[i]]= np.dot(alloc,test_means) - Llist[i]* np.dot(np.dot(alloc,test_covs),alloc.T)/2.0\n",
    "                W_val_merit['W_objective'][headers[i]]= np.sum(np.log1p(Llist[i]*np.dot(test_returns,alloc.T)))/nrows                        \n",
    "                W_val_prtns[i]=np.dot(test_returns,alloc)\n",
    "\n",
    "    return(M_val_merit,W_val_merit,M_val_prtns,W_val_prtns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OPTIONALLY PRINT VALIDATION RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_output(M_val_merit,W_val_merit,\n",
    "        M_val_prtns,W_val_prtns,learn_M_merit,learn_W_merit,test_length,Llist):\n",
    "    print(' ')\n",
    "    print('M_val_merit')\n",
    "    print(M_val_merit)\n",
    "    print(' ')\n",
    "    print('W_val_merit')\n",
    "    print(W_val_merit)\n",
    "    print(' ')\n",
    "    \n",
    "    print('MV OPTIMIZED MERIT CHANGES FROM LEARNING SAMPLE SOLUTION')\n",
    "    MVopt_delta_merit=np.subtract(np.array(M_val_merit),np.array(learn_M_merit))\n",
    "    MV_D_merit=pd.DataFrame(MVopt_delta_merit,columns=M_val_merit.columns, index=M_val_merit.index)\n",
    "    #following necessary because np.round fails on NaN\n",
    "    with pd.option_context('display.float_format', '{:,.5f}'.format):\n",
    "        print(MV_D_merit)\n",
    "    print(' ')\n",
    "    \n",
    "    print('LLS OPTIMIZED MERIT CHANGES FROM LEARNING SAMPLE SOLUTION')\n",
    "    LLSopt_delta_merit=np.subtract(np.array(W_val_merit),np.array(learn_W_merit))\n",
    "    LLS_D_merit=pd.DataFrame(LLSopt_delta_merit,columns=W_val_merit.columns, index=W_val_merit.index)\n",
    "    with pd.option_context('display.float_format', '{:,.5f}'.format):\n",
    "        print(LLS_D_merit)\n",
    "    \n",
    "    print(' ')\n",
    "    print('CHECK FOR MV-OPTIMIZED RETURN LESS THAN SURPLUS IN TEST SAMPLE')\n",
    "    print('M_val_prtns')\n",
    "    for i in range(len(M_val_prtns)):\n",
    "        print('Llist[i]: ',Llist[i])\n",
    "        for j in range(test_length):\n",
    "            if M_val_prtns[i,j]< -(1/Llist[i]):\n",
    "                print(M_val_prtns[i,j],' j: ',j)\n",
    "    print(' ')\n",
    "    print('CHECK FOR LLS-OPTIMIZED RETURN LESS THAN SURPLUS IN TEST SAMPLE')\n",
    "    print('W_val_prtns')\n",
    "    for i in range(len(W_val_prtns)):\n",
    "        print('Llist[i]: ',Llist[i])\n",
    "        for j in range(test_length):\n",
    "            if W_val_prtns[i,j]< -(1/Llist[i]):\n",
    "                print(W_val_prtns[i,j],' j: ',j)\n",
    "    print(' ')\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RESEARCH RECORDKEEPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_parameters(journalfile,logfile,sample,meanfile,codefile,sourcefile,sourcetype,Llist,splithalf,mod_method,long_only,return_interval,worst):\n",
    "    print(' ')    \n",
    "    print(f'{journalfile=}')\n",
    "    print(f'{logfile=}')\n",
    "    print(f'{sample=}')\n",
    "    print(f'{meanfile=}')\n",
    "    print(f'{codefile=}')\n",
    "    print(f'{sourcefile=}')\n",
    "    print(f'{sourcetype=}')\n",
    "    print(f'{Llist=}')\n",
    "    print(f'{splithalf=}')\n",
    "    print(f'{mod_method=}')\n",
    "    print(f'{long_only=}') \n",
    "    print(f'{return_interval=}')\n",
    "    print(f'{worst=}')\n",
    "    print(' ')\n",
    "    return\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAIN PROGRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def higher_moments(params={}):\n",
    "\n",
    "    journalfile=params.get('journalfile')\n",
    "    logfile=params.get('logfile')\n",
    "    sample=params.get('sample')\n",
    "    meanfile=params.get('meanfile')\n",
    "    codefile=params.get('codefile')\n",
    "    sourcefile=params.get('sourcefile')\n",
    "    sourcetype=params.get('sourcetype')    \n",
    "    Llist=params.get('Llist')\n",
    "    splithalf=params.get('splithalf')\n",
    "    mod_method=params.get('mod_method')\n",
    "    long_only=params.get('long_only')\n",
    "    return_interval=params.get('return_interval')\n",
    "    worst=params.get('worst')\n",
    "   \n",
    "    #See import dependencies in first cell\n",
    "\n",
    "    #record run description in journalfile\n",
    "    orig_stdout = sys.stdout\n",
    "    e=open(journalfile, 'a')\n",
    "    sys.stdout=e\n",
    "    print_parameters(journalfile,logfile,sample,meanfile,codefile,sourcefile,\n",
    "        sourcetype,Llist,splithalf,mod_method,long_only,return_interval,worst)\n",
    "    e.close()\n",
    "\n",
    "    #record results in logfile\n",
    "    f = open(logfile, 'w')\n",
    "    sys.stdout = f\n",
    "\n",
    "    #record control parameters\n",
    "    print_parameters(journalfile,logfile,sample,meanfile,codefile,sourcefile,\n",
    "        sourcetype,Llist,splithalf,mod_method,long_only,return_interval,worst)\n",
    "\n",
    "    #Read asset mean returns assumed in sub-means option\n",
    "    try:\n",
    "        mean_lookup=load_asset_means(meanfile)\n",
    "        print('Means if sub_means modification used:')\n",
    "        print (mean_lookup)\n",
    "    except:\n",
    "        print('Main error: failed to load meanfile')\n",
    "        raise\n",
    "    \n",
    "    #Read in asset categories and members\n",
    "    try:\n",
    "        lookup_group,members=load_asset_codes(codefile)\n",
    "        print(' ')\n",
    "        print('Asset groups and members:')\n",
    "        print(members)\n",
    "        print(' ')\n",
    "    except:\n",
    "        print('Error: Failed to load codefile')\n",
    "        raise\n",
    "        \n",
    "    #Read in Prices or Returns, based on sourcetype, adjusted for dividends and interest if possible\n",
    "    \n",
    "    if sourcetype=='PRICES':\n",
    "        #prices=load_source(sourcefile) \n",
    "        #Rearrange prices by asset class for greater interpretability\n",
    "        prices2=rearrange(members,load_source(sourcefile) )\n",
    "        #Calculate return matrix\n",
    "        returns_df=calculate_returns(prices2,return_interval)\n",
    "    elif sourcetype=='RETURNS':\n",
    "        returns_df=rearrange(members,load_source(sourcefile))\n",
    "    else:\n",
    "        print('UNABLE TO DETERMINE SOURCE TYPE')\n",
    "        raise\n",
    "        \n",
    "    # optionally...\n",
    "    print(' ')\n",
    "    print('RETURNS SAMPLE')\n",
    "    print(returns_df.head())\n",
    "    print(' ')\n",
    "    print(returns_df.tail())\n",
    "    print(' ')\n",
    "\n",
    "    #splithalf if applied, 0: nosplit, 1:first half for learning, 2nd half for testing,\n",
    "    #   2: 2nd half for learning, first for testing\n",
    "    learn_returns,test_returns=learning_returns(returns_df.values,splithalf)\n",
    "    learn_returns_df=pd.DataFrame(learn_returns,columns=returns_df.columns)\n",
    "    print('LEARN RETURNS DESCRIPTION')\n",
    "    print(learn_returns_df.describe())\n",
    "\n",
    "    print(' ')\n",
    "    test_returns_df=None\n",
    "    if splithalf>0:\n",
    "        print(' ')\n",
    "        print('TEST RETURNS DESCRIPTION')\n",
    "        test_returns_df=pd.DataFrame(test_returns,columns=returns_df.columns)\n",
    "        print(test_returns_df.describe())\n",
    "    \n",
    "    #calculate and show moment characteristics of learn_returns\n",
    "    print(' ')\n",
    "    print('RETURN MATRIX PARAMETERS BEFORE MODIFICATION')\n",
    "    learn_means,learn_covs,learn_skews,learn_kurts,combined=rtn_summary(learn_returns,returns_df.columns)\n",
    "    print(combined.head(len(returns_df.columns)))\n",
    "    print(' ')\n",
    "\n",
    "    #May modify returns\n",
    "    if mod_method!='mirror':\n",
    "        mlearn_returns_df=modify_returns(learn_returns_df,mod_method,members,mean_lookup)\n",
    "        #redo description    \n",
    "        print('MODIFIED LEARN RETURNS DESCRIPTION')\n",
    "        print(mlearn_returns_df.describe())\n",
    "        print(' ')\n",
    "    else:\n",
    "        mlearn_returns_df=learn_returns_df\n",
    "        mlearn_means,mlearn_covs,mlearn_skews,lmearn_kurts,combined=rtn_summary(\n",
    "            mlearn_returns_df.values,returns_df.columns)\n",
    "        print(combined.head(len(returns_df.columns)))\n",
    "        print(' ')    \n",
    "    \n",
    "    # Do mean-variance and log leveraged surplus optimizations\n",
    "    (wpreturns,mpreturns,learn_walloc,learn_malloc,\n",
    "        learn_W_merit,learn_M_merit) = find_best_allocation(learn_returns_df,\n",
    "        mlearn_returns_df,long_only,worst,Llist,lookup_group)\n",
    "\n",
    "    #describe portfolio return statistics for different leveragesTHIS IS WHERE SHOULD USE ORIG DATA FOR MERIT\n",
    "    describe_portfolio_returns(wpreturns,mpreturns,learn_W_merit,learn_M_merit,Llist)\n",
    "\n",
    "    # optionally test possibly modified learning-sample optimal allocations on test-sample\n",
    "    if splithalf>0:\n",
    "        M_val_merit,W_val_merit,M_val_prtns,W_val_prtns = merit_of_learned_allocations(\n",
    "            learn_malloc,learn_walloc, test_returns, Llist = Llist)\n",
    "        test_length=len(test_returns)\n",
    "        out=validation_output(M_val_merit,W_val_merit,M_val_prtns,W_val_prtns,\n",
    "            learn_M_merit,learn_W_merit,test_length,Llist)\n",
    "\n",
    "    #close logfile and print it on terminal\n",
    "    f.close()\n",
    "    sys.stdout = orig_stdout\n",
    "\n",
    "    h=open(logfile,'r')\n",
    "    for line in h:\n",
    "        if len(line)>0:          \n",
    "            print(line[:-1])          \n",
    "    h.close()\n",
    "        \n",
    "    optimizer_output={\n",
    "        \"params\":params,\n",
    "        \"members\":members,\n",
    "        \"learn_returns_df\":learn_returns_df,\n",
    "        \"test_returns_df\":test_returns_df,\n",
    "        \"wpreturns\":wpreturns,\n",
    "        \"mpreturns\":mpreturns,\n",
    "        \"learn_walloc\":learn_walloc,\n",
    "        \"learn_malloc\":learn_malloc,\n",
    "        \"learn_W_merit\":learn_W_merit,\n",
    "        \"learn_M_merit\":learn_M_merit,\n",
    "    }\n",
    "    if splithalf>0:\n",
    "        optimizer_output[\"W_val_merit\"]=W_val_merit,\n",
    "        optimizer_output[\"M_val_merit\"]=M_val_merit,\n",
    "        optimizer_output[\"W_val_prtns\"]=W_val_prtns,\n",
    "        optimizer_output[\"M_val_prtns\"]=M_val_prtns,    \n",
    "    \n",
    "    print(' ')\n",
    "    print('higher_moments DONE!')\n",
    "    \n",
    "    return optimizer_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SET PARAMETERS AND CALL RESEARCH OPTIMIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "journalfile='JOURNAL.txt'\n",
      "logfile='RUNxx.txt'\n",
      "sample='20YR'\n",
      "meanfile='CDATA20/asset_mean.csv'\n",
      "codefile='CDATA20/equiv.csv'\n",
      "sourcefile='CDATA20/prices.csv'\n",
      "sourcetype='PRICES'\n",
      "Llist=[1, 2, 4, 8, 16]\n",
      "splithalf=1\n",
      "mod_method='mirror'\n",
      "long_only=True\n",
      "return_interval=1\n",
      "worst=-0.99\n",
      " \n",
      "Means if sub_means modification used:\n",
      "{'STOCK': 0.64, 'BOND': 0.29, 'CASH': 0.17, 'JUNK': 0.35, 'NOGROUP': nan}\n",
      " \n",
      "Asset groups and members:\n",
      "{'BOND': ['VFIIX', 'VUSTX', 'VWESX', 'VFITX'], 'CASH': ['VWSTX'], 'JUNK': ['VWEHX', 'VWAHX'], 'STOCK': ['XLE', 'EWJ', 'XLP', 'XLV', 'XLY', 'DIA', 'XLK', 'SPY']}\n",
      " \n",
      " \n",
      "RETURNS SAMPLE\n",
      "               VFIIX     VUSTX     VWESX     VFITX     VWSTX     VWEHX  \\\n",
      "Date                                                                     \n",
      "1999-01-01  0.008281  0.009904  0.028578  0.006580  0.004880  0.019328   \n",
      "1999-02-01 -0.007106 -0.047315 -0.036633 -0.030332  0.001924 -0.005854   \n",
      "1999-03-01  0.006325 -0.015088 -0.005120  0.005414  0.000833  0.007603   \n",
      "1999-04-01  0.004371  0.013424  0.004758  0.003062  0.002508  0.013409   \n",
      "1999-05-01 -0.008280 -0.017152 -0.016449 -0.013952  0.001801 -0.016409   \n",
      "\n",
      "               VWAHX       XLE       EWJ       XLP       XLV       XLY  \\\n",
      "Date                                                                     \n",
      "1999-01-01  0.018370 -0.065596  0.025385 -0.013233  0.048077  0.051435   \n",
      "1999-02-01 -0.002812 -0.008597 -0.035715 -0.010496  0.001147 -0.006257   \n",
      "1999-03-01 -0.000547  0.137284  0.135803 -0.002947  0.026346  0.047510   \n",
      "1999-04-01  0.004415  0.152157  0.043478 -0.033165  0.035714  0.027344   \n",
      "1999-05-01 -0.006809 -0.021583 -0.057292 -0.010410 -0.030712 -0.045261   \n",
      "\n",
      "                 DIA       XLK       SPY  \n",
      "Date                                      \n",
      "1999-01-01  0.020846  0.159004  0.038665  \n",
      "1999-02-01 -0.002542 -0.099173 -0.032069  \n",
      "1999-03-01  0.054013  0.074312  0.038948  \n",
      "1999-04-01  0.102672  0.005978  0.040492  \n",
      "1999-05-01 -0.022916  0.003396 -0.022866  \n",
      " \n",
      "               VFIIX     VUSTX     VWESX     VFITX     VWSTX     VWEHX  \\\n",
      "Date                                                                     \n",
      "2019-09-01  0.000288 -0.026225 -0.019730 -0.006933 -0.000569  0.004441   \n",
      "2019-10-01  0.003036 -0.011064  0.001166  0.001750  0.001897  0.005968   \n",
      "2019-11-01  0.001142 -0.003858  0.003874 -0.003576  0.001328  0.006129   \n",
      "2019-12-01  0.000097 -0.032736 -0.021278 -0.003690  0.001770  0.012744   \n",
      "2020-01-01  0.003040  0.023923  0.027542  0.006886  0.001895  0.006059   \n",
      "\n",
      "               VWAHX       XLE       EWJ       XLP       XLV       XLY  \\\n",
      "Date                                                                     \n",
      "2019-09-01 -0.006489  0.029923  0.052300  0.011528 -0.005188  0.009366   \n",
      "2019-10-01  0.000085 -0.011992  0.034191  0.001658  0.055626  0.004564   \n",
      "2019-11-01  0.002738  0.016046  0.012781  0.013734  0.050026  0.013239   \n",
      "2019-12-01  0.000938  0.019528 -0.003197  0.015806  0.023821  0.024255   \n",
      "2020-01-01  0.010179  0.054330  0.014834  0.000668  0.010776  0.009377   \n",
      "\n",
      "                 DIA       XLK       SPY  \n",
      "Date                                      \n",
      "2019-09-01  0.021806  0.012574  0.014772  \n",
      "2019-10-01  0.007231  0.042229  0.026825  \n",
      "2019-11-01  0.039374  0.053663  0.036198  \n",
      "2019-12-01  0.016649  0.039814  0.024021  \n",
      "2020-01-01  0.009668  0.013003  0.010474  \n",
      " \n",
      "SPLITHALF CODE:  1\n",
      "LEARN RETURNS DESCRIPTION\n",
      "            VFIIX       VUSTX       VWESX       VFITX       VWSTX       VWEHX  \\\n",
      "count  126.000000  126.000000  126.000000  126.000000  126.000000  126.000000   \n",
      "mean     0.004745    0.005472    0.004866    0.004929    0.002571    0.003222   \n",
      "std      0.009015    0.027532    0.028050    0.014616    0.002591    0.025761   \n",
      "min     -0.030771   -0.086092   -0.093105   -0.039042   -0.005859   -0.155371   \n",
      "25%     -0.000589   -0.011489   -0.011008   -0.004476    0.001163   -0.005812   \n",
      "50%      0.005207    0.008255    0.006673    0.005525    0.002541    0.006953   \n",
      "75%      0.010115    0.019783    0.018459    0.013459    0.004018    0.014176   \n",
      "max      0.038096    0.121016    0.131348    0.056121    0.011195    0.085158   \n",
      "\n",
      "            VWAHX         XLE         EWJ         XLP         XLV         XLY  \\\n",
      "count  126.000000  126.000000  126.000000  126.000000  126.000000  126.000000   \n",
      "mean     0.003390    0.009200    0.001992    0.000815    0.001881    0.001477   \n",
      "std      0.014268    0.066158    0.056560    0.037535    0.042909    0.058550   \n",
      "min     -0.051652   -0.185375   -0.155722   -0.120137   -0.145144   -0.173442   \n",
      "25%     -0.004520   -0.030271   -0.033043   -0.013141   -0.022961   -0.030870   \n",
      "50%      0.005543    0.008925   -0.002922    0.004514    0.006130   -0.000352   \n",
      "75%      0.011804    0.052764    0.043478    0.023510    0.029698    0.036537   \n",
      "max      0.047120    0.167776    0.135803    0.093821    0.116004    0.191629   \n",
      "\n",
      "              DIA         XLK         SPY  \n",
      "count  126.000000  126.000000  126.000000  \n",
      "mean     0.002077   -0.000595    0.000118  \n",
      "std      0.044655    0.083006    0.046098  \n",
      "min     -0.134507   -0.249061   -0.160355  \n",
      "25%     -0.022081   -0.041342   -0.019755  \n",
      "50%      0.002761    0.002897    0.002314  \n",
      "75%      0.027651    0.047588    0.027384  \n",
      "max      0.104567    0.247675    0.107214  \n",
      " \n",
      " \n",
      "TEST RETURNS DESCRIPTION\n",
      "            VFIIX       VUSTX       VWESX       VFITX         VWSTX  \\\n",
      "count  127.000000  127.000000  127.000000  127.000000  1.270000e+02   \n",
      "mean     0.002826    0.005861    0.007174    0.002768  9.325057e-04   \n",
      "std      0.008025    0.034668    0.023628    0.014368  1.591293e-03   \n",
      "min     -0.027264   -0.078636   -0.051701   -0.060327 -4.877419e-03   \n",
      "25%     -0.001053   -0.018835   -0.007151   -0.004072  1.910570e-07   \n",
      "50%      0.002981    0.004205    0.004505    0.001750  1.009892e-03   \n",
      "75%      0.007406    0.022230    0.022496    0.009266  2.032277e-03   \n",
      "max      0.023465    0.107073    0.072565    0.051065  4.869105e-03   \n",
      "\n",
      "            VWEHX       VWAHX         XLE         EWJ         XLP         XLV  \\\n",
      "count  127.000000  127.000000  127.000000  127.000000  127.000000  127.000000   \n",
      "mean     0.006773    0.004916    0.005806    0.005742    0.010743    0.012885   \n",
      "std      0.015944    0.012341    0.057959    0.039344    0.031484    0.036439   \n",
      "min     -0.040926   -0.044163   -0.147582   -0.104944   -0.097405   -0.097632   \n",
      "25%     -0.001613   -0.000436   -0.026626   -0.019518   -0.009373   -0.004624   \n",
      "50%      0.006499    0.005647    0.011958    0.008696    0.012753    0.012712   \n",
      "75%      0.015767    0.011326    0.042901    0.031100    0.032856    0.034203   \n",
      "max      0.057944    0.051849    0.196099    0.096596    0.074714    0.092982   \n",
      "\n",
      "              XLY         DIA         XLK         SPY  \n",
      "count  127.000000  127.000000  127.000000  127.000000  \n",
      "mean     0.015617    0.012278    0.015187    0.012338  \n",
      "std      0.042623    0.035209    0.042966    0.036630  \n",
      "min     -0.100093   -0.085144   -0.087725   -0.093343  \n",
      "25%     -0.009289   -0.003054   -0.010436   -0.006490  \n",
      "50%      0.016139    0.011471    0.018338    0.014772  \n",
      "75%      0.045711    0.032429    0.042481    0.032895  \n",
      "max      0.123171    0.097583    0.112615    0.114886  \n",
      " \n",
      "RETURN MATRIX PARAMETERS BEFORE MODIFICATION\n",
      "   TICKER    MEAN   STDEV  SKEW   KURT  VFIIX  VUSTX  VWESX  VFITX  VWSTX  \\\n",
      "0   VFIIX  0.0047  0.0090 -0.22   5.16   1.00   0.83   0.73   0.89   0.55   \n",
      "1   VUSTX  0.0055  0.0274  0.09   5.86   0.83   1.00   0.85   0.89   0.41   \n",
      "2   VWESX  0.0049  0.0279  0.13   7.09   0.73   0.85   1.00   0.69   0.40   \n",
      "3   VFITX  0.0049  0.0146 -0.04   3.88   0.89   0.89   0.69   1.00   0.55   \n",
      "4   VWSTX  0.0026  0.0026 -0.06   4.76   0.55   0.41   0.40   0.55   1.00   \n",
      "5   VWEHX  0.0032  0.0257 -1.65  14.50   0.12   0.00   0.41  -0.05   0.12   \n",
      "6   VWAHX  0.0034  0.0142 -0.86   6.08   0.42   0.30   0.47   0.35   0.62   \n",
      "7     XLE  0.0092  0.0659 -0.14   3.29  -0.09  -0.11   0.07  -0.18  -0.23   \n",
      "8     EWJ  0.0020  0.0563 -0.01   2.63   0.02  -0.01   0.22  -0.09  -0.17   \n",
      "9     XLP  0.0008  0.0374 -0.83   4.27  -0.02  -0.02   0.10  -0.06  -0.15   \n",
      "10    XLV  0.0019  0.0427 -0.46   3.94  -0.07  -0.13   0.14  -0.21  -0.09   \n",
      "11    XLY  0.0015  0.0583  0.02   3.84  -0.06  -0.14   0.11  -0.20  -0.11   \n",
      "12    DIA  0.0021  0.0445 -0.42   3.70  -0.15  -0.20   0.04  -0.28  -0.21   \n",
      "13    XLK -0.0006  0.0827 -0.14   3.57  -0.16  -0.20   0.01  -0.28  -0.19   \n",
      "14    SPY  0.0001  0.0459 -0.46   3.71  -0.11  -0.17   0.10  -0.26  -0.20   \n",
      "\n",
      "    VWEHX  VWAHX   XLE   EWJ   XLP   XLV   XLY   DIA   XLK   SPY  \n",
      "0    0.12   0.42 -0.09  0.02 -0.02 -0.07 -0.06 -0.15 -0.16 -0.11  \n",
      "1    0.00   0.30 -0.11 -0.01 -0.02 -0.13 -0.14 -0.20 -0.20 -0.17  \n",
      "2    0.41   0.47  0.07  0.22  0.10  0.14  0.11  0.04  0.01  0.10  \n",
      "3   -0.05   0.35 -0.18 -0.09 -0.06 -0.21 -0.20 -0.28 -0.28 -0.26  \n",
      "4    0.12   0.62 -0.23 -0.17 -0.15 -0.09 -0.11 -0.21 -0.19 -0.20  \n",
      "5    1.00   0.48  0.40  0.46  0.28  0.56  0.57  0.53  0.47  0.61  \n",
      "6    0.48   1.00  0.11  0.08  0.03  0.10  0.11  0.05  0.03  0.12  \n",
      "7    0.40   0.11  1.00  0.45  0.33  0.38  0.36  0.57  0.34  0.56  \n",
      "8    0.46   0.08  0.45  1.00  0.26  0.50  0.47  0.57  0.50  0.63  \n",
      "9    0.28   0.03  0.33  0.26  1.00  0.43  0.42  0.55  0.19  0.52  \n",
      "10   0.56   0.10  0.38  0.50  0.43  1.00  0.67  0.78  0.61  0.78  \n",
      "11   0.57   0.11  0.36  0.47  0.42  0.67  1.00  0.81  0.65  0.84  \n",
      "12   0.53   0.05  0.57  0.57  0.55  0.78  0.81  1.00  0.72  0.93  \n",
      "13   0.47   0.03  0.34  0.50  0.19  0.61  0.65  0.72  1.00  0.84  \n",
      "14   0.61   0.12  0.56  0.63  0.52  0.78  0.84  0.93  0.84  1.00  \n",
      " \n",
      "   TICKER    MEAN   STDEV  SKEW   KURT  VFIIX  VUSTX  VWESX  VFITX  VWSTX  \\\n",
      "0   VFIIX  0.0047  0.0090 -0.22   5.16   1.00   0.83   0.73   0.89   0.55   \n",
      "1   VUSTX  0.0055  0.0274  0.09   5.86   0.83   1.00   0.85   0.89   0.41   \n",
      "2   VWESX  0.0049  0.0279  0.13   7.09   0.73   0.85   1.00   0.69   0.40   \n",
      "3   VFITX  0.0049  0.0146 -0.04   3.88   0.89   0.89   0.69   1.00   0.55   \n",
      "4   VWSTX  0.0026  0.0026 -0.06   4.76   0.55   0.41   0.40   0.55   1.00   \n",
      "5   VWEHX  0.0032  0.0257 -1.65  14.50   0.12   0.00   0.41  -0.05   0.12   \n",
      "6   VWAHX  0.0034  0.0142 -0.86   6.08   0.42   0.30   0.47   0.35   0.62   \n",
      "7     XLE  0.0092  0.0659 -0.14   3.29  -0.09  -0.11   0.07  -0.18  -0.23   \n",
      "8     EWJ  0.0020  0.0563 -0.01   2.63   0.02  -0.01   0.22  -0.09  -0.17   \n",
      "9     XLP  0.0008  0.0374 -0.83   4.27  -0.02  -0.02   0.10  -0.06  -0.15   \n",
      "10    XLV  0.0019  0.0427 -0.46   3.94  -0.07  -0.13   0.14  -0.21  -0.09   \n",
      "11    XLY  0.0015  0.0583  0.02   3.84  -0.06  -0.14   0.11  -0.20  -0.11   \n",
      "12    DIA  0.0021  0.0445 -0.42   3.70  -0.15  -0.20   0.04  -0.28  -0.21   \n",
      "13    XLK -0.0006  0.0827 -0.14   3.57  -0.16  -0.20   0.01  -0.28  -0.19   \n",
      "14    SPY  0.0001  0.0459 -0.46   3.71  -0.11  -0.17   0.10  -0.26  -0.20   \n",
      "\n",
      "    VWEHX  VWAHX   XLE   EWJ   XLP   XLV   XLY   DIA   XLK   SPY  \n",
      "0    0.12   0.42 -0.09  0.02 -0.02 -0.07 -0.06 -0.15 -0.16 -0.11  \n",
      "1    0.00   0.30 -0.11 -0.01 -0.02 -0.13 -0.14 -0.20 -0.20 -0.17  \n",
      "2    0.41   0.47  0.07  0.22  0.10  0.14  0.11  0.04  0.01  0.10  \n",
      "3   -0.05   0.35 -0.18 -0.09 -0.06 -0.21 -0.20 -0.28 -0.28 -0.26  \n",
      "4    0.12   0.62 -0.23 -0.17 -0.15 -0.09 -0.11 -0.21 -0.19 -0.20  \n",
      "5    1.00   0.48  0.40  0.46  0.28  0.56  0.57  0.53  0.47  0.61  \n",
      "6    0.48   1.00  0.11  0.08  0.03  0.10  0.11  0.05  0.03  0.12  \n",
      "7    0.40   0.11  1.00  0.45  0.33  0.38  0.36  0.57  0.34  0.56  \n",
      "8    0.46   0.08  0.45  1.00  0.26  0.50  0.47  0.57  0.50  0.63  \n",
      "9    0.28   0.03  0.33  0.26  1.00  0.43  0.42  0.55  0.19  0.52  \n",
      "10   0.56   0.10  0.38  0.50  0.43  1.00  0.67  0.78  0.61  0.78  \n",
      "11   0.57   0.11  0.36  0.47  0.42  0.67  1.00  0.81  0.65  0.84  \n",
      "12   0.53   0.05  0.57  0.57  0.55  0.78  0.81  1.00  0.72  0.93  \n",
      "13   0.47   0.03  0.34  0.50  0.19  0.61  0.65  0.72  1.00  0.84  \n",
      "14   0.61   0.12  0.56  0.63  0.52  0.78  0.84  0.93  0.84  1.00  \n",
      " \n",
      "RUNNING MEAN-VARIANCE OPTIMIZATION\n",
      "Risk Aversion:  1\n",
      "Risk Aversion:  2\n",
      "Risk Aversion:  4\n",
      "Risk Aversion:  8\n",
      "Risk Aversion:  16\n",
      " \n",
      "RUNNING EXPECTED SURPLUS GROWTH OPTIMIZATION\n",
      "Risk Aversion:  1\n",
      "Risk Aversion:  2\n",
      "Risk Aversion:  4\n",
      "Risk Aversion:  8\n",
      "Risk Aversion:  16\n",
      " \n",
      "ALLOCATIONS TO MAXIMIZE MEAN-VARIANCE\n",
      "          L:1      L:2      L:4      L:8     L:16\n",
      "VFIIX  0.0000  0.00000  0.00000  0.65856  0.90905\n",
      "VUSTX  0.1533  0.49018  0.16554 -0.00000 -0.00000\n",
      "VWESX  0.0000  0.00000 -0.00000 -0.00000 -0.00000\n",
      "VFITX  0.0000  0.00000  0.53417  0.18350  0.00000\n",
      "VWSTX -0.0000 -0.00000  0.00000  0.00000 -0.00000\n",
      "VWEHX  0.0000 -0.00000  0.00000 -0.00000 -0.00000\n",
      "VWAHX -0.0000  0.00000  0.00000  0.00000 -0.00000\n",
      "XLE    0.8467  0.50982  0.30029  0.15794  0.09095\n",
      "EWJ   -0.0000  0.00000 -0.00000 -0.00000 -0.00000\n",
      "XLP   -0.0000  0.00000  0.00000  0.00000 -0.00000\n",
      "XLV   -0.0000 -0.00000 -0.00000  0.00000 -0.00000\n",
      "XLY   -0.0000  0.00000 -0.00000  0.00000 -0.00000\n",
      "DIA   -0.0000  0.00000  0.00000 -0.00000 -0.00000\n",
      "XLK   -0.0000  0.00000 -0.00000  0.00000 -0.00000\n",
      "SPY   -0.0000  0.00000 -0.00000 -0.00000 -0.00000\n",
      " \n",
      "ALLOCATIONS TO MAXIMIZE EXPECTED SURPLUS GROWTH\n",
      "           L:1      L:2      L:4      L:8     L:16\n",
      "VFIIX  0.00000  0.00000  0.00000  0.65753  0.91534\n",
      "VUSTX  0.15083  0.49128  0.14129  0.00000 -0.00000\n",
      "VWESX  0.00000  0.00000  0.00000  0.00000 -0.00000\n",
      "VFITX  0.00000  0.00000  0.56123  0.18644  0.00000\n",
      "VWSTX  0.00000  0.00000  0.00000 -0.00000 -0.00000\n",
      "VWEHX  0.00000  0.00000  0.00000 -0.00000 -0.00000\n",
      "VWAHX  0.00000  0.00000  0.00000  0.00000 -0.00000\n",
      "XLE    0.84917  0.50872  0.29748  0.15603  0.08466\n",
      "EWJ    0.00000  0.00000 -0.00000 -0.00000 -0.00000\n",
      "XLP    0.00000  0.00000 -0.00000 -0.00000 -0.00000\n",
      "XLV    0.00000  0.00000 -0.00000 -0.00000 -0.00000\n",
      "XLY    0.00000  0.00000 -0.00000 -0.00000 -0.00000\n",
      "DIA    0.00000  0.00000 -0.00000 -0.00000 -0.00000\n",
      "XLK    0.00000  0.00000 -0.00000 -0.00000 -0.00000\n",
      "SPY    0.00000  0.00000 -0.00000 -0.00000 -0.00000\n",
      " \n",
      "INCREMENTAL ALLOCATIONS\n",
      "          L:1     L:2     L:4     L:8    L:16\n",
      "VFIIX  0.0000  0.0000  0.0000 -0.0010  0.0063\n",
      "VUSTX -0.0025  0.0011 -0.0242  0.0000 -0.0000\n",
      "VWESX  0.0000  0.0000  0.0000  0.0000 -0.0000\n",
      "VFITX  0.0000  0.0000  0.0271  0.0029  0.0000\n",
      "VWSTX  0.0000  0.0000  0.0000 -0.0000 -0.0000\n",
      "VWEHX  0.0000  0.0000  0.0000 -0.0000 -0.0000\n",
      "VWAHX  0.0000  0.0000  0.0000  0.0000 -0.0000\n",
      "XLE    0.0025 -0.0011 -0.0028 -0.0019 -0.0063\n",
      "EWJ    0.0000  0.0000 -0.0000 -0.0000 -0.0000\n",
      "XLP    0.0000  0.0000 -0.0000 -0.0000 -0.0000\n",
      "XLV    0.0000  0.0000 -0.0000 -0.0000 -0.0000\n",
      "XLY    0.0000  0.0000 -0.0000 -0.0000 -0.0000\n",
      "DIA    0.0000  0.0000 -0.0000 -0.0000 -0.0000\n",
      "XLK    0.0000  0.0000 -0.0000 -0.0000 -0.0000\n",
      "SPY    0.0000  0.0000 -0.0000 -0.0000 -0.0000\n",
      " \n",
      "IN-SAMPLE ALLOCATION MERIT FROM MEAN-VARIANCE\n",
      "     W_objective M_objective\n",
      "L:1   0.00706003  0.00707641\n",
      "L:2    0.0122294  0.00615227\n",
      "L:4    0.0212606   0.0053709\n",
      "L:8    0.0380465  0.00484938\n",
      "L:16   0.0675908  0.00439754\n",
      " \n",
      "IN-SAMPLE ALLOCATION MERIT FROM EXPECTED SURPLUS GROWTH\n",
      "     W_objective M_objective\n",
      "L:1   0.00706004  0.00707639\n",
      "L:2    0.0122294  0.00615226\n",
      "L:4     0.021262  0.00537057\n",
      "L:8    0.0380471  0.00484931\n",
      "L:16   0.0676143  0.00439609\n",
      " \n",
      "INCREMENTAL MERIT\n",
      "     W_objective M_objective\n",
      "L:1      0.00000    -0.00000\n",
      "L:2      0.00000    -0.00000\n",
      "L:4      0.00000    -0.00000\n",
      "L:8      0.00000    -0.00000\n",
      "L:16     0.00002    -0.00000\n",
      " \n",
      "COMPARE PORTFOLIO STATISTICS\n",
      " \n",
      "IN_SAMPLE SURPLUS GROWTH OBJECTIVE WITH MEAN-VARIANCE OPTIMIZATION\n",
      " \n",
      "Leverage     Q\n",
      "     L:1 0.055\n",
      "     L:2 0.069\n",
      "     L:4 0.084\n",
      "     L:8 0.096\n",
      "    L:16 0.143\n",
      " \n",
      "COMPOSITION BY RETURN DISTRIBUTION MOMENTS:\n",
      " \n",
      " Leverage  Exp_Log_Gr     First    Second     Third    Fourth      Residual\n",
      "      1.0    0.007060  0.008591 -0.001513 -0.000010 -0.000008 -3.488001e-07\n",
      "      2.0    0.012229  0.014638 -0.002352 -0.000035 -0.000020 -1.763530e-06\n",
      "      4.0    0.021261  0.024894 -0.003514 -0.000067 -0.000047 -5.568669e-06\n",
      "      8.0    0.038046  0.042926 -0.004612 -0.000158 -0.000091 -1.895555e-05\n",
      "     16.0    0.067591  0.079187 -0.010200 -0.000641 -0.000516 -2.390649e-04\n",
      " \n",
      "IN-SAMPLE SURPLUS GROWTH OBJECTIVE WITH SURPLUS GROWTH OPTIMIZATION\n",
      " \n",
      "Leverage     Q\n",
      "     L:1 0.055\n",
      "     L:2 0.068\n",
      "     L:4 0.083\n",
      "     L:8 0.095\n",
      "    L:16 0.140\n",
      " \n",
      "COMPOSITION BY RETURN DISTRIBUTION MOMENTS:\n",
      " \n",
      " Leverage  Exp_Log_Gr     First    Second     Third    Fourth      Residual\n",
      "      1.0    0.007060  0.008601 -0.001522 -0.000010 -0.000008 -3.531656e-07\n",
      "      2.0    0.012229  0.014630 -0.002344 -0.000035 -0.000020 -1.750227e-06\n",
      "      4.0    0.021262  0.024795 -0.003420 -0.000064 -0.000044 -5.147136e-06\n",
      "      8.0    0.038047  0.042865 -0.004555 -0.000156 -0.000089 -1.837397e-05\n",
      "     16.0    0.067614  0.078773 -0.009848 -0.000604 -0.000488 -2.176032e-04\n",
      " \n",
      " \n",
      "M_val_merit\n",
      "     W_objective M_objective\n",
      "L:1   0.00470529  0.00470754\n",
      "L:2    0.0101615  0.00510117\n",
      "L:4    0.0141885  0.00356684\n",
      "L:8    0.0223808  0.00281979\n",
      "L:16   0.0399659   0.0025418\n",
      " \n",
      "W_val_merit\n",
      "     W_objective M_objective\n",
      "L:1   0.00469714  0.00469934\n",
      "L:2    0.0101665  0.00510373\n",
      "L:4    0.0138992  0.00349321\n",
      "L:8    0.0223763  0.00281943\n",
      "L:16   0.0399254  0.00254103\n",
      " \n",
      "MV OPTIMIZED MERIT CHANGES FROM LEARNING SAMPLE SOLUTION\n",
      "     W_objective M_objective\n",
      "L:1     -0.00235    -0.00237\n",
      "L:2     -0.00207    -0.00105\n",
      "L:4     -0.00707    -0.00180\n",
      "L:8     -0.01567    -0.00203\n",
      "L:16    -0.02762    -0.00186\n",
      " \n",
      "LLS OPTIMIZED MERIT CHANGES FROM LEARNING SAMPLE SOLUTION\n",
      "     W_objective M_objective\n",
      "L:1     -0.00236    -0.00238\n",
      "L:2     -0.00206    -0.00105\n",
      "L:4     -0.00736    -0.00188\n",
      "L:8     -0.01567    -0.00203\n",
      "L:16    -0.02769    -0.00186\n",
      " \n",
      "CHECK FOR MV-OPTIMIZED RETURN LESS THAN SURPLUS IN TEST SAMPLE\n",
      "M_val_prtns\n",
      "Llist[i]:  1\n",
      "Llist[i]:  2\n",
      "Llist[i]:  4\n",
      "Llist[i]:  8\n",
      "Llist[i]:  16\n",
      " \n",
      "CHECK FOR LLS-OPTIMIZED RETURN LESS THAN SURPLUS IN TEST SAMPLE\n",
      "W_val_prtns\n",
      "Llist[i]:  1\n",
      "Llist[i]:  2\n",
      "Llist[i]:  4\n",
      "Llist[i]:  8\n",
      "Llist[i]:  16\n",
      " \n",
      " \n",
      "higher_moments DONE!\n"
     ]
    }
   ],
   "source": [
    "#set parameters\n",
    "\n",
    "params=dict(\n",
    "    journalfile='JOURNAL.txt',\n",
    "    logfile='RUNxx.txt',\n",
    "    sample='20YR',\n",
    "    meanfile='CDATA20/asset_mean.csv',\n",
    "    codefile='CDATA20/equiv.csv',\n",
    "    sourcefile='CDATA20/prices.csv',\n",
    "    sourcetype='PRICES',\n",
    "    Llist=[1,2,4,8,16],\n",
    "    splithalf=1,\n",
    "    mod_method='mirror',\n",
    "    long_only=True,\n",
    "    return_interval=1,\n",
    "    worst=(-0.99),\n",
    "    )\n",
    "#run main program\n",
    "optimizer_output=higher_moments(params)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
